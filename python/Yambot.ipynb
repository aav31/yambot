{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "09833dfd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap>:488: RuntimeWarning: Your system is avx2 capable but pygame was not built with support for it. The performance of some of your blits could be adversely affected. Consider enabling compile time detection with environment variables like PYGAME_DETECT_AVX2=1 if you are compiling without cross compilation.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from dataclasses import dataclass\n",
    "from enum import Enum\n",
    "from typing import Tuple, Dict, Optional, List\n",
    "from numpy.typing import NDArray\n",
    "import gymnasium as gym\n",
    "from gymnasium import spaces, ObservationWrapper, RewardWrapper\n",
    "from gymnasium.wrappers import NormalizeReward\n",
    "import unittest\n",
    "import time\n",
    "import pygame\n",
    "from stable_baselines3.common.env_checker import check_env\n",
    "from sb3_contrib import MaskablePPO\n",
    "from sb3_contrib.common.envs import InvalidActionEnvDiscrete, InvalidActionEnvMultiDiscrete\n",
    "from sb3_contrib.common.maskable.evaluation import evaluate_policy\n",
    "from sb3_contrib.common.maskable.utils import get_action_masks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aba18c4",
   "metadata": {},
   "source": [
    "### Which spaces to use?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bc4483d",
   "metadata": {},
   "source": [
    "I think you can use any observation space, but the action space cannot be a dict or a tuple. `Box` space might be better as there seems to be more algorithms that support it. Though `MultiDiscrete` seems to be easier to describe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b4102b93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 5,  2,  4,  5,  0,  2,  1, 11, 10,  0])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# keep: np.array # action type 1 and 2, array of length 6 saying which dice we keep\n",
    "# announce: bool = False # roll_number / action type 1\n",
    "# announce_row: ROW = ROW.YAMB # roll_number / action type 1\n",
    "# row_to_fill: ROW = ROW.YAMB # roll_number / action type 3 \n",
    "# col_to_fill: COL = COL.DOLJE # roll_number / action type 3\n",
    "\n",
    "# the action space can't be a tuple or dictionary, which is tricky\n",
    "number_of_ones_to_keep_range = {\"low\" : 0, \"high\": 5}\n",
    "number_of_twos_to_keep_range = {\"low\" : 0, \"high\": 5}\n",
    "number_of_threes_to_keep_range = {\"low\" : 0, \"high\": 5}\n",
    "number_of_fours_to_keep_range = {\"low\" : 0, \"high\": 5}\n",
    "number_of_fives_to_keep_range = {\"low\" : 0, \"high\": 5}\n",
    "number_of_sixes_to_keep_range = {\"low\" : 0, \"high\": 5}\n",
    "announce_range = {\"low\" : 0, \"high\": 1}\n",
    "announce_row_range = {\"low\" : 0, \"high\": 13}\n",
    "row_to_fill_range = {\"low\": 0, \"high\": 13}\n",
    "col_to_fill_range = {\"low\": 0, \"high\": 3}\n",
    "\n",
    "low = np.array(\n",
    "[\n",
    "    number_of_ones_to_keep_range[\"low\"],\n",
    "    number_of_twos_to_keep_range[\"low\"],\n",
    "    number_of_threes_to_keep_range[\"low\"],\n",
    "    number_of_fours_to_keep_range[\"low\"],\n",
    "    number_of_fives_to_keep_range[\"low\"],\n",
    "    number_of_sixes_to_keep_range[\"low\"],\n",
    "    announce_range[\"low\"],\n",
    "    announce_row_range[\"low\"],\n",
    "    row_to_fill_range[\"low\"],\n",
    "    col_to_fill_range[\"low\"],\n",
    "]\n",
    ")\n",
    "\n",
    "high = np.array(\n",
    "[\n",
    "    number_of_ones_to_keep_range[\"high\"],\n",
    "    number_of_twos_to_keep_range[\"high\"],\n",
    "    number_of_threes_to_keep_range[\"high\"],\n",
    "    number_of_fours_to_keep_range[\"high\"],\n",
    "    number_of_fives_to_keep_range[\"high\"],\n",
    "    number_of_sixes_to_keep_range[\"high\"],\n",
    "    announce_range[\"high\"],\n",
    "    announce_row_range[\"high\"],\n",
    "    row_to_fill_range[\"high\"],\n",
    "    col_to_fill_range[\"high\"],\n",
    "]\n",
    ")\n",
    "\n",
    "action_space = spaces.Box(low=low, high=high, dtype=int)\n",
    "action_space.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57ca0242",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3,  4,  1,  4,  0,  0,  1, 11,  9,  2], dtype=int64)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action_space = spaces.MultiDiscrete(np.array([6, 6, 6, 6, 6, 6, 2, 14, 14, 4]))\n",
    "action_space.sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d6f65cb",
   "metadata": {},
   "source": [
    "### Maskable action space\n",
    "Might need this for Maskable PPO from `sb3_contrib`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "38221ec8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 2, 1, 2, 0, 1, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num1s = np.array([1, 1, 1, 0, 0, 0], dtype=np.int8)\n",
    "num2s = np.array([1, 1, 1, 0, 0, 0], dtype=np.int8)\n",
    "num3s = np.array([1, 1, 1, 0, 0, 0], dtype=np.int8)\n",
    "num4s = np.array([1, 1, 1, 0, 0, 0], dtype=np.int8)\n",
    "num5s = np.array([1, 1, 1, 0, 0, 0], dtype=np.int8)\n",
    "num6s = np.array([1, 1, 1, 0, 0, 0], dtype=np.int8)\n",
    "announce = np.array([1, 0], dtype=np.int8)\n",
    "announce_row = np.array([1]*14, dtype=np.int8)\n",
    "row_to_fill = np.array([1] + 13 * [0], dtype=np.int8)\n",
    "col_to_fill = np.array([1, 0, 0, 0], dtype=np.int8)\n",
    "mask = (num1s, num2s, num3s, num4s, num5s, num6s, announce, announce_row, row_to_fill, col_to_fill)\n",
    "action_space.sample(mask=mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f72f4de2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('announced', 0),\n",
       "             ('announced_row', 5),\n",
       "             ('grid',\n",
       "              array([[  92,  113,  106],\n",
       "                     [   3,  -34,   57],\n",
       "                     [ 106,  -35,  -79],\n",
       "                     [  49,  -12,  -74],\n",
       "                     [ 107,   -8,   67],\n",
       "                     [ -70,  133,  127],\n",
       "                     [  47,  113,  -79],\n",
       "                     [ -10,  -70,  132],\n",
       "                     [ -57,  120,  -64],\n",
       "                     [ 132,  121,  -93],\n",
       "                     [  57,    5,  128],\n",
       "                     [  99,  130, -143],\n",
       "                     [ -42,  136, -136],\n",
       "                     [-112,   33,  127]])),\n",
       "             ('roll', array([5, 1, 1, 4, 1, 5])),\n",
       "             ('roll_number', 1),\n",
       "             ('turn_number', 2)])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spaces.Dict({\n",
    "            \"turn_number\": spaces.Discrete(14*3,start=0),\n",
    "            \"roll_number\": spaces.Discrete(3,start=0),\n",
    "            \"grid\": spaces.Box(low=-145, high=145, shape=(14, 3), dtype=int),\n",
    "            \"roll\": spaces.Box(low=0, high=5, shape=(6,), dtype=int),\n",
    "            \"announced\": spaces.Discrete(2,start=0),\n",
    "            \"announced_row\": spaces.Discrete(14, start=0),\n",
    "}).sample()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24480d4d",
   "metadata": {},
   "source": [
    "# `YambEnv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "90507226",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ROW(Enum):\n",
    "    \"\"\"Enum representing each row in yamb\n",
    "    \"\"\"\n",
    "    ONES=0\n",
    "    TWOS=1\n",
    "    THREES=2\n",
    "    FOURS=3\n",
    "    FIVES=4\n",
    "    SIXES=5\n",
    "    MAX=6\n",
    "    MIN=7\n",
    "    DVAPARA=8\n",
    "    TRIS=9\n",
    "    SKALA=10\n",
    "    FULL=11\n",
    "    POKER=12\n",
    "    YAMB=13\n",
    "    \n",
    "class COL(Enum):\n",
    "    \"\"\"Enum representing each col in yamb\n",
    "    \"\"\"\n",
    "    DOLJE=0\n",
    "    GORE=1\n",
    "    SLOBODNO=2\n",
    "    NAJAVA=3\n",
    "    \n",
    "\n",
    "class YambEnv(gym.Env):\n",
    "    \"\"\"\n",
    "    :param turn_number: This tells us which turn we are on. There are 14 * 4 turns in yamb each consisting of 3 rolls.\n",
    "    :param roll_number: Each round in yamb consists of three rolls. This tells you which roll we are on.\n",
    "    :param grid: This is the 14 * 4 grid in yamb which needs to be filled out. -145 indicates not filled.\n",
    "    :param roll: This tells us the roll we just had in multinomial format. This means roll[2] is the number of 3s.\n",
    "    :param announced: This tells us whether we have announced in our current turn.\n",
    "    :param announced_row: This tells us the row we have announced in our current turn.\n",
    "    \"\"\"\n",
    "    RENDER_FPS = 10\n",
    "    NAN = -145\n",
    "    ACTION_ANNOUNCE_IDX = 6\n",
    "    ACTION_ANNOUNCE_ROW_IDX = 7\n",
    "    ACTION_ROW_COL_FILL_IDX = 8\n",
    "    SCREEN_WIDTH = 640\n",
    "    SCREEN_HEIGHT = 480\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.turn_number = 0\n",
    "        self.roll_number = 0\n",
    "        self.grid = np.full((len(ROW), len(COL)), self.NAN)\n",
    "        self.roll = np.array([0, 0, 0, 0, 0, 0])\n",
    "        self.announced = 0\n",
    "        self.announced_row = 0\n",
    "        \n",
    "        self.observation_space = spaces.Dict({\n",
    "            \"turn_number\": spaces.Discrete(len(ROW)*len(COL),start=0),\n",
    "            \"roll_number\": spaces.Discrete(3,start=0),\n",
    "            \"grid\": spaces.Box(low=-145, high=145, shape=(len(ROW), len(COL)), dtype=int),\n",
    "            \"roll\": spaces.Box(low=0, high=5, shape=(6,), dtype=int),\n",
    "            \"announced\": spaces.Discrete(2,start=0),\n",
    "            \"announced_row\": spaces.Discrete(len(ROW), start=0),\n",
    "        })\n",
    "        \n",
    "        # [num1s, num2s, num3s, num4s, num5s, num6s, announce, announce_row, row_col_fill]\n",
    "        self.action_space = spaces.MultiDiscrete(np.array([6, 6, 6, 6, 6, 6, 2, len(ROW), len(ROW) * len(COL)]))\n",
    "        \n",
    "        self.truncation_penalty = -1000\n",
    "        \n",
    "        # pygame parameters and objects\n",
    "        self.screen = None\n",
    "        self.clock = None\n",
    "    \n",
    "    def reset(self, seed=None, options=None) -> Tuple[dict, dict]:\n",
    "        \"\"\"Reset environment to initial state - remember this also includes rolling the dice\n",
    "        \n",
    "        :return: observation of the initial state along with auxiliary information\n",
    "        \"\"\"\n",
    "        self.turn_number = 0\n",
    "        self.roll_number = 0\n",
    "        for row in ROW:\n",
    "            for col in COL:\n",
    "                self.grid[row.value, col.value] = self.NAN\n",
    "        self.roll = np.random.multinomial(5, [1/6.]*6)\n",
    "        self.announced = 0\n",
    "        self.announced_row = 0\n",
    "        return self.get_observation(), {}\n",
    "    \n",
    "    def step(self, action : NDArray[np.int64]) -> Tuple[dict, float, bool, bool, dict]:\n",
    "        \"\"\" Run one timestep of the environment's dynamics - in total there are 56 turns, and 3 rolls within each turn\n",
    "        \n",
    "        :param action: numpy array of length 9\n",
    "            [num1s, num2s, num3s, num4s, num5s, num6s, announce, announce_row, row_col_fill]\n",
    "        \n",
    "        :return: observation, reward, terminated, truncated, info\n",
    "            observation:dict\n",
    "            reward:float score - prev score or self.truncation_penalty if the game finishes because of a bad action\n",
    "            terminated:bool true when the game finished properly\n",
    "            truncated:bool true when the game finished due to unforseen circumstances; action was out of bounds\n",
    "            info:dict other relevant information for example the score / why the game truncated?\n",
    "        \"\"\"\n",
    "        \n",
    "        prev_score = self.get_score()\n",
    "        \n",
    "        valid, info = True, {}\n",
    "        if self.roll_number == 0:\n",
    "            valid = self.step_1_valid(action, info)\n",
    "        \n",
    "        if self.roll_number == 1:\n",
    "            valid = self.step_2_valid(action, info)\n",
    "        \n",
    "        if self.roll_number == 2:\n",
    "            valid = self.step_3_valid(action[YambEnv.ACTION_ROW_COL_FILL_IDX], info)\n",
    "        \n",
    "        if not valid:\n",
    "            return self.get_observation(), self.truncation_penalty, False, True, info\n",
    "        \n",
    "        # if the action is valid, we can mutate the state\n",
    "        if self.roll_number == 0:\n",
    "            self.roll_number += 1\n",
    "            keep = action[:self.ACTION_ANNOUNCE_IDX]\n",
    "            number_of_dice_to_roll = sum(self.roll - keep)\n",
    "            self.roll = np.random.multinomial(number_of_dice_to_roll, [1/6.]*6) + keep\n",
    "            self.announced = action[self.ACTION_ANNOUNCE_IDX]\n",
    "            self.announced_row = action[self.ACTION_ANNOUNCE_ROW_IDX]\n",
    "        elif self.roll_number == 1:\n",
    "            self.roll_number += 1\n",
    "            keep = action[:self.ACTION_ANNOUNCE_IDX]\n",
    "            number_of_dice_to_roll = sum(self.roll - keep)\n",
    "            self.roll = np.random.multinomial(number_of_dice_to_roll, [1/6.]*6) + keep\n",
    "        elif self.roll_number == 2:\n",
    "            # we are moving on to the next turn\n",
    "            self.roll_number = 0\n",
    "            self.turn_number += 1\n",
    "            self.announced = 0\n",
    "            self.announced_row = 0\n",
    "            r, c = YambEnv.convert_row_col_fill(action[YambEnv.ACTION_ROW_COL_FILL_IDX])\n",
    "            self.grid[r, c] = self.get_grid_square_value(r, self.roll)\n",
    "            self.roll = np.random.multinomial(5, [1/6.]*6)\n",
    "        \n",
    "        info[\"score\"] = self.get_score()\n",
    "        reward = info[\"score\"] - prev_score\n",
    "        terminated = True if self.turn_number >= len(ROW)*len(COL) else False\n",
    "        \n",
    "        if self.render_mode == \"human\":\n",
    "            self.render()\n",
    "            \n",
    "        return self.get_observation(), reward, terminated, False, info\n",
    "    \n",
    "    def render(self):\n",
    "        \"\"\"Displays the state of the game - there is no interaction with the user here\n",
    "        \"\"\"\n",
    "        if self.screen is None:\n",
    "            pygame.init()\n",
    "            self.screen = pygame.display.set_mode((self.SCREEN_WIDTH, self.SCREEN_HEIGHT), pygame.RESIZABLE)\n",
    "            \n",
    "        if self.clock is None:\n",
    "            self.clock = pygame.time.Clock()\n",
    "            \n",
    "        cell_size = 32\n",
    "        dot_radius = 2\n",
    "        black = (0, 0, 0)\n",
    "        white = (255, 255, 255)\n",
    "        self.screen.fill(white)\n",
    "        \n",
    "        font = pygame.font.Font(None, 24)\n",
    "        text = font.render(f\"TURN: {self.turn_number}, ROLL: {self.roll_number}\", True, black)\n",
    "        text_rect = text.get_rect()\n",
    "        text_rect.topleft = (self.SCREEN_WIDTH//2, cell_size)\n",
    "        self.screen.blit(text, text_rect)\n",
    "        \n",
    "        text = font.render(f\"SCORE: {self.get_score()}\", True, black)\n",
    "        text_rect = text.get_rect()\n",
    "        text_rect.topleft = (self.SCREEN_WIDTH//2, 2*cell_size)\n",
    "        self.screen.blit(text, text_rect)\n",
    "        \n",
    "        text = font.render(f\"ANNOUNCED: {bool(self.announced)}\", True, black)\n",
    "        text_rect = text.get_rect()\n",
    "        text_rect.topleft = (self.SCREEN_WIDTH//2, 4*cell_size)\n",
    "        self.screen.blit(text, text_rect)\n",
    "        \n",
    "        if self.announced == 1:\n",
    "            text = font.render(f\"ANNOUNCED ROW: {ROW(self.announced_row)}\", True, black)\n",
    "            text_rect = text.get_rect()\n",
    "            text_rect.topleft = (self.SCREEN_WIDTH//2, 5*cell_size)\n",
    "            self.screen.blit(text, text_rect)\n",
    "        \n",
    "        \n",
    "        \n",
    "        # draw rows\n",
    "        font = pygame.font.Font(None, 12)\n",
    "        for row in ROW:\n",
    "            rect = pygame.Rect(0, (1+row.value)*cell_size, 2*cell_size, cell_size)\n",
    "            text = font.render(str(row.value) + \". \" + row.name, True, black)\n",
    "            pygame.draw.rect(self.screen, black, rect, 1)\n",
    "            self.screen.blit(text, rect.move(cell_size//4, cell_size//4))\n",
    "            \n",
    "        # draw cols\n",
    "        for col in COL:\n",
    "            rect = pygame.Rect((2+2*col.value)*cell_size, 0, 2*cell_size, cell_size)\n",
    "            text = font.render(str(col.value) + \". \" + col.name, True, black)\n",
    "            pygame.draw.rect(self.screen, black, rect, 1)\n",
    "            self.screen.blit(text, rect.move(cell_size//4, cell_size//4))\n",
    "            \n",
    "        # fill out the grid\n",
    "        font = pygame.font.Font(None, 20)\n",
    "        for row in ROW:\n",
    "            for col in COL:\n",
    "                rect = pygame.Rect((2+2*col.value)*cell_size, (1+row.value)*cell_size, 2*cell_size, cell_size)\n",
    "                s = \"\" if self.grid[row.value, col.value] == self.NAN else str(self.grid[row.value, col.value])\n",
    "                text = font.render(s, True, black)\n",
    "                pygame.draw.rect(self.screen, black, rect, 1)\n",
    "                self.screen.blit(text, rect.move(cell_size//4, cell_size//4))\n",
    "                \n",
    "        # draw roll\n",
    "        def draw_dot(position):\n",
    "            pygame.draw.circle(self.screen, black, position, dot_radius)\n",
    "\n",
    "        def draw_one(x, y):\n",
    "            draw_dot((x + cell_size//2, y + cell_size//2))\n",
    "\n",
    "        def draw_two(x, y):\n",
    "            draw_dot((x + cell_size//4, y + cell_size//4))\n",
    "            draw_dot((x + cell_size*3//4, y + cell_size*3//4))\n",
    "\n",
    "        def draw_three(x, y):\n",
    "            draw_dot((x + cell_size//4, y + cell_size//4))\n",
    "            draw_dot((x + cell_size//2, y + cell_size//2))\n",
    "            draw_dot((x + cell_size*3//4, y + cell_size*3//4))\n",
    "\n",
    "        def draw_four(x, y):\n",
    "            draw_dot((x + cell_size//4, y + cell_size//4))\n",
    "            draw_dot((x + cell_size*3//4, y + cell_size//4))\n",
    "            draw_dot((x + cell_size//4, y + cell_size*3//4))\n",
    "            draw_dot((x + cell_size*3//4, y + cell_size*3//4))\n",
    "\n",
    "        def draw_five(x, y):\n",
    "            draw_dot((x + cell_size//4, y + cell_size//4))\n",
    "            draw_dot((x + cell_size*3//4, y + cell_size//4))\n",
    "            draw_dot((x + cell_size//2, y + cell_size//2))\n",
    "            draw_dot((x + cell_size//4, y + cell_size*3//4))\n",
    "            draw_dot((x + cell_size*3//4, y + cell_size*3//4))\n",
    "\n",
    "        def draw_six(x, y):\n",
    "            draw_dot((x + cell_size//4, y + cell_size//4))\n",
    "            draw_dot((x + cell_size*3//4, y + cell_size//4))\n",
    "            draw_dot((x + cell_size//4, y + cell_size//2))\n",
    "            draw_dot((x + cell_size*3//4, y + cell_size//2))\n",
    "            draw_dot((x + cell_size//4, y + cell_size*3//4))\n",
    "            draw_dot((x + cell_size*3//4, y + cell_size*3//4))\n",
    "        \n",
    "        top_left_x, top_left_y = YambEnv.SCREEN_WIDTH//2, YambEnv.SCREEN_HEIGHT//2\n",
    "        for i, count in enumerate(self.roll):\n",
    "            for die in range(count):\n",
    "                rect = pygame.Rect(top_left_x, top_left_y, cell_size, cell_size)\n",
    "                pygame.draw.rect(self.screen, (0, 0, 0), rect, 1)\n",
    "                \n",
    "                if (i+1)==1: draw_one(top_left_x, top_left_y)\n",
    "                if (i+1)==2: draw_two(top_left_x, top_left_y)\n",
    "                if (i+1)==3: draw_three(top_left_x, top_left_y)\n",
    "                if (i+1)==4: draw_four(top_left_x, top_left_y)\n",
    "                if (i+1)==5: draw_five(top_left_x, top_left_y)\n",
    "                if (i+1)==6: draw_six(top_left_x, top_left_y)\n",
    "                    \n",
    "                top_left_x += cell_size\n",
    "                \n",
    "            \n",
    "        self.clock.tick(YambEnv.RENDER_FPS)\n",
    "        pygame.display.flip()\n",
    "        \n",
    "    \n",
    "    def close(self):\n",
    "        if self.screen is not None:\n",
    "            pygame.display.quit()\n",
    "            pygame.quit()\n",
    "        \n",
    "    def get_observation(self) -> dict:\n",
    "        observation = {\n",
    "            \"turn_number\": self.turn_number,\n",
    "            \"roll_number\": self.roll_number,\n",
    "            \"grid\": self.grid,\n",
    "            \"roll\": self.roll,\n",
    "            \"announced\": self.announced,\n",
    "            \"announced_row\": self.announced_row,\n",
    "        }\n",
    "        return observation\n",
    "    \n",
    "    def action_masks(self) -> List[bool]:\n",
    "        \"\"\"Returns a one hot encoded list whether an action is valid\n",
    "        \n",
    "        :return: list of size sum([6, 6, 6, 6, 6, 6, 2, 14, 56])\n",
    "        \"\"\"\n",
    "        num1s = [False] * 6\n",
    "        num2s = [False] * 6\n",
    "        num3s = [False] * 6\n",
    "        num4s = [False] * 6\n",
    "        num5s = [False] * 6\n",
    "        num6s = [False] * 6\n",
    "        announce = [False] * 2\n",
    "        announce_row = [False] * len(ROW)\n",
    "        row_col_fill = [False] * len(ROW) * len(COL)\n",
    "        \n",
    "        # can only keep dice that you have\n",
    "        if (self.roll_number == 0) or (self.roll_number == 1):\n",
    "            num1s = [True] * (self.roll[0] + 1) + [False] * (5 - self.roll[0])\n",
    "            num2s = [True] * (self.roll[1] + 1) + [False] * (5 - self.roll[1])\n",
    "            num3s = [True] * (self.roll[2] + 1) + [False] * (5 - self.roll[2])\n",
    "            num4s = [True] * (self.roll[3] + 1) + [False] * (5 - self.roll[3])\n",
    "            num5s = [True] * (self.roll[4] + 1) + [False] * (5 - self.roll[4])\n",
    "            num6s = [True] * (self.roll[5] + 1) + [False] * (5 - self.roll[5])\n",
    "        \n",
    "        if self.roll_number == 0:\n",
    "            announce_row = [self.valid_announce_row(i) for i in range(len(ROW))]\n",
    "            announce = [not self.need_to_announce(), any(announce_row)]\n",
    "            \n",
    "        if self.roll_number == 2:\n",
    "            for i in range(len(COL)*len(ROW)):\n",
    "                row_col_fill[i] = self.step_3_valid(i, {})\n",
    "                \n",
    "        mask = num1s + num2s + num3s + num4s + num5s + num6s + announce + announce_row + row_col_fill\n",
    "        return mask\n",
    "        \n",
    "    def step_1_valid(self, action: NDArray[np.int64], info: dict) -> bool:\n",
    "        \"\"\"Checks whether an action of type 1 is valid\n",
    "        \n",
    "        :param action: numpy array of length 9\n",
    "            [num1s, num2s, num3s, num4s, num5s, num6s, announce, announce_row, row_col_fill]\n",
    "        \n",
    "        :return: whether the action was valid or not, truncation reason will be added to info dict\n",
    "        \n",
    "        unused: row_col_fill\n",
    "        \"\"\"\n",
    "        keep = action[:self.ACTION_ANNOUNCE_IDX]\n",
    "        if any( (self.roll - keep) < 0 ):\n",
    "            info[\"truncation_reason\"] = f\"Can't keep {keep} when you only have {self.roll}\"\n",
    "            return False\n",
    "        \n",
    "        if action[self.ACTION_ANNOUNCE_IDX] == 1:\n",
    "            if not self.valid_announce_row(action[self.ACTION_ANNOUNCE_ROW_IDX]):\n",
    "                info[\"truncation_reason\"] = f\"Announce row {ROW(action[self.ACTION_ANNOUNCE_ROW_IDX])} not valid\"\n",
    "                return False\n",
    "            \n",
    "        if action[self.ACTION_ANNOUNCE_IDX] == 0:\n",
    "            if self.need_to_announce():\n",
    "                info[\"truncation_reason\"] = \"Only najava column left so must use it\"\n",
    "                return False\n",
    "            \n",
    "        return True\n",
    "    \n",
    "    def step_2_valid(self, action: NDArray[np.int64], info: dict) -> bool:\n",
    "        \"\"\"Checks whether an action of type 2 is valid\n",
    "        \n",
    "        :param action: numpy array of length 9\n",
    "            [num1s, num2s, num3s, num4s, num5s, num6s, announce, announce_row, row_col_fill]\n",
    "        \n",
    "        :return: whether the action was valid or not, truncation reason will be added to info dict\n",
    "        \n",
    "        unused: announce, announce_row, row_col_fill\n",
    "        \"\"\"\n",
    "        keep = action[:self.ACTION_ANNOUNCE_IDX]\n",
    "        if any( (self.roll - keep) < 0 ):\n",
    "            info[\"truncation_reason\"] = f\"Can't keep {keep} when you only have {self.roll}\"\n",
    "            return False\n",
    "        \n",
    "        return True\n",
    "    \n",
    "    def step_3_valid(self, row_col_fill: int, info: dict) -> bool:\n",
    "        \"\"\"Checks whether an action of type 3 is valid\n",
    "        \n",
    "        :param row_col_fill: int indicating which row and col of the grid to fill out\n",
    "        \n",
    "        :return: whether the action was valid or not, truncation reason will be added to info dict\n",
    "        \"\"\"\n",
    "        r, c = YambEnv.convert_row_col_fill(row_col_fill)\n",
    "        if self.grid[r, c] != self.NAN:\n",
    "            info[\"truncation_reason\"] = f\"{r}, {c} already filled in \"\n",
    "            return False\n",
    "        \n",
    "        if (c == COL.GORE.value) and (r != self.get_next_gore()):\n",
    "            info[\"truncation_reason\"] = f\"Gore needed {ROW(self.get_next_gore())} but trying {ROW(r)}\"\n",
    "            return False\n",
    "        \n",
    "        if (c == COL.DOLJE.value) and (r != self.get_next_dolje()):\n",
    "            info[\"truncation_reason\"] = f\"Dolje needed {ROW(self.get_next_dolje())} but trying {ROW(r)}\"\n",
    "            return False\n",
    "        \n",
    "        if self.announced and ((c != COL.NAJAVA.value) or (r != self.announced_row)):\n",
    "            info[\"truncation_reason\"] = f\"Announced {ROW(self.announced_row)} but trying to fill {ROW(r)}, {COL(c)}\"\n",
    "            return False\n",
    "        \n",
    "        if (self.announced==0) and (c == COL.NAJAVA.value):\n",
    "            info[\"truncation_reason\"] = f\"Have not announced so cannot fill out najava column\"\n",
    "            return False\n",
    "        \n",
    "        return True\n",
    "    \n",
    "    def valid_announce_row(self, row: int) -> bool:\n",
    "        \"\"\"\n",
    "        :param row: a row which you which to announce\n",
    "        \n",
    "        :return: bool indicated whether you can actually announce that row\n",
    "        \"\"\"\n",
    "        if row not in ROW:\n",
    "            return False\n",
    "        \n",
    "        if self.grid[row, COL.NAJAVA.value] == self.NAN:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "        \n",
    "    def need_to_announce(self) -> bool:\n",
    "        \"\"\"You must announce on your first roll when the rest of the grid has been filled\n",
    "        :return: whether you need to announce on your first roll\n",
    "        \"\"\"\n",
    "        for col in [COL.DOLJE, COL.GORE, COL.SLOBODNO]:\n",
    "            for row in ROW:\n",
    "                if self.grid[row.value, col.value] == self.NAN:\n",
    "                    # there's something you can fill out\n",
    "                    return False\n",
    "                \n",
    "        return True\n",
    "    \n",
    "    def get_score(self) -> int:\n",
    "        \"\"\"\n",
    "        :return: game score thus far, anything with an nan will be assigned zero\n",
    "        \"\"\"\n",
    "        result = 0\n",
    "        for col in COL:\n",
    "            A = 0\n",
    "            for row in [ROW.ONES, ROW.TWOS, ROW.THREES, ROW.FOURS, ROW.FIVES, ROW.SIXES]:\n",
    "                A += 0 if self.grid[row.value, col.value] == self.NAN else self.grid[row.value, col.value]\n",
    "                \n",
    "            if (A >= 60):\n",
    "                A += 30\n",
    "            \n",
    "            if (self.grid[ROW.MAX.value, col.value] == self.NAN) or \\\n",
    "            (self.grid[ROW.MIN.value, col.value] == self.NAN) or \\\n",
    "            (self.grid[ROW.ONES.value, col.value] == self.NAN):\n",
    "                B = 0\n",
    "            else:\n",
    "                B = self.grid[ROW.MAX.value, col.value] - self.grid[ROW.MIN.value, col.value]\n",
    "                B *= self.grid[ROW.ONES.value, col.value] \n",
    "            \n",
    "            C = 0\n",
    "            for row in [ROW.DVAPARA, ROW.TRIS, ROW.SKALA, ROW.FULL, ROW.POKER, ROW.YAMB]:\n",
    "                C += 0 if self.grid[row.value, col.value] == self.NAN else self.grid[row.value, col.value]\n",
    "                \n",
    "            result = result + A + B + C\n",
    "                \n",
    "        return result\n",
    "    \n",
    "    def get_next_dolje(self) -> Optional[int]:\n",
    "        \"\"\"\n",
    "        Gets the next row we need to fill out in the dolje column, if we've completed it return nan\n",
    "        \"\"\"\n",
    "        for row in ROW:\n",
    "            if self.grid[row.value, COL.DOLJE.value] == self.NAN: return row.value\n",
    "        \n",
    "        return np.nan\n",
    "    \n",
    "    def get_next_gore(self) -> Optional[int]:\n",
    "        \"\"\"\n",
    "        Gets the next row we need to fill out in the gore column, if we've completed it return nan\n",
    "        \"\"\"\n",
    "        for row in reversed(ROW):\n",
    "            if self.grid[row.value, COL.GORE.value] == self.NAN: return row.value\n",
    "        \n",
    "        return np.nan\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_grid_square_value(row: int, cnts: np.array) -> int:\n",
    "        \"\"\"\n",
    "        :param row: which row do you want the grid square value for\n",
    "        :param cnts: array of size six which tells you tells you mapping of face value to how many dice\n",
    "        :return: grid square value\n",
    "        \"\"\"\n",
    "        \n",
    "        if row == ROW.ONES.value:\n",
    "            return 1 * cnts[0]\n",
    "        elif row == ROW.TWOS.value:\n",
    "            return 2 * cnts[1]\n",
    "        elif row == ROW.THREES.value:\n",
    "            return 3 * cnts[2]\n",
    "        elif row == ROW.FOURS.value:\n",
    "            return 4 * cnts[3]\n",
    "        elif row == ROW.FIVES.value:\n",
    "            return 5 * cnts[4]\n",
    "        elif row == ROW.SIXES.value:\n",
    "            return 6 * cnts[5]\n",
    "        elif row == ROW.MAX.value:\n",
    "            return sum( (i+1)*item for i, item in enumerate(cnts) )\n",
    "        elif row == ROW.MIN.value:\n",
    "            return sum( (i+1)*item for i, item in enumerate(cnts) )\n",
    "        elif row == ROW.DVAPARA.value:\n",
    "            return YambEnv.dvapara(cnts)\n",
    "        elif row == ROW.TRIS.value:\n",
    "            return YambEnv.tris(cnts)\n",
    "        elif row == ROW.SKALA.value:\n",
    "            return YambEnv.skala(cnts)\n",
    "        elif row == ROW.FULL.value:\n",
    "            return YambEnv.full(cnts)\n",
    "        elif row == ROW.POKER.value:\n",
    "            return YambEnv.poker(cnts)\n",
    "        elif row == ROW.YAMB.value:\n",
    "            return YambEnv.yamb(cnts)\n",
    "        else:\n",
    "            raise IndexError(f\"Row {row} not found in possible rows\")\n",
    "    \n",
    "    @staticmethod\n",
    "    def dvapara(cnts : np.array) -> int:\n",
    "        if not (sum(cnts >= 2) >= 2): return 0\n",
    "        s = 0\n",
    "        for i, cnt in enumerate(cnts):\n",
    "            if cnt >= 2:\n",
    "                s += 2 * (i+1)\n",
    "        return s + 10\n",
    "    \n",
    "    @staticmethod\n",
    "    def tris(cnts : np.array) -> int:\n",
    "        if not any(cnts >= 3): return 0\n",
    "        s = 0\n",
    "        for i, cnt in enumerate(cnts):\n",
    "            if cnt >= 3:\n",
    "                s += 3 * (i+1)\n",
    "                \n",
    "        return s + 20\n",
    "    \n",
    "    @staticmethod\n",
    "    def skala(cnts : np.array) -> int:\n",
    "        if all(np.array([1,1,1,1,1,0]) == cnts):\n",
    "            return 45\n",
    "        elif all(np.array([0,1,1,1,1,1]) == cnts):\n",
    "            return 50\n",
    "        else:\n",
    "            return 0\n",
    "    \n",
    "    @staticmethod\n",
    "    def full(cnts : np.array) -> int:\n",
    "        if not (any(cnts == 3) * any(cnts == 2)): return 0\n",
    "        s = sum( (i+1)*item for i, item in enumerate(cnts) )\n",
    "        return s + 40\n",
    "    \n",
    "    @staticmethod\n",
    "    def poker(cnts : np.array) -> int:\n",
    "        if not any(cnts >= 4): return 0\n",
    "        s = 0\n",
    "        for i, cnt in enumerate(cnts):\n",
    "            if cnt >= 4:\n",
    "                s += 4 * (i+1)\n",
    "        \n",
    "        return s + 50\n",
    "    \n",
    "    @staticmethod\n",
    "    def yamb(cnts : np.array) -> int:\n",
    "        if not any(cnts >= 5): return 0\n",
    "        s = sum( (i+1)*item for i, item in enumerate(cnts) )\n",
    "        return s + 60\n",
    "    \n",
    "    @staticmethod\n",
    "    def convert_row_col_fill(row_col_to_fill: int) -> Tuple[int, int]:\n",
    "        \"\"\"Converts a single index representing a grid square to fill in into two indices\n",
    "        representing a row and column to fill\n",
    "        \n",
    "        :param row_col_to_fill: single index representing a grid square we want to fill\n",
    "        \n",
    "        :return: row we want to fill in, col we want to fill in\n",
    "        \"\"\"\n",
    "        assert 0 <= row_col_to_fill < len(ROW) * len(COL)\n",
    "        col_to_fill, row_to_fill = divmod(row_col_to_fill, len(ROW))\n",
    "        return row_to_fill, col_to_fill\n",
    "    \n",
    "    @staticmethod\n",
    "    def convert_row_fill_col_fill(row_to_fill: int, col_to_fill: int) -> int:\n",
    "        \"\"\"Converts two indices representing a row and column to fill into a single\n",
    "        index representing a grid square to fill\n",
    "        \n",
    "        :param row_to_fill: row we want to fill in\n",
    "        :param col_to_fill: col we want to fill in\n",
    "        \n",
    "        :return: single index representing a grid square we want to fill\n",
    "        \"\"\"\n",
    "        assert 0 <= row_to_fill < len(ROW)\n",
    "        assert 0 <= col_to_fill < len(COL)\n",
    "        return row_to_fill + len(ROW) * col_to_fill\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c125f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestYambEnv(unittest.TestCase):\n",
    "    def test_convert_row_col_fill(self):\n",
    "        row, col = YambEnv.convert_row_col_fill(0)\n",
    "        self.assertEqual(0, row)\n",
    "        self.assertEqual(0, col)\n",
    "        \n",
    "        row, col = YambEnv.convert_row_col_fill(14)\n",
    "        self.assertEqual(0, row)\n",
    "        self.assertEqual(1, col)\n",
    "        \n",
    "        row, col = YambEnv.convert_row_col_fill(55)\n",
    "        self.assertEqual(13, row)\n",
    "        self.assertEqual(3, col)\n",
    "        \n",
    "    def test_convert_row_fill_col_fill(self):\n",
    "        idx = YambEnv.convert_row_fill_col_fill(1, 0)\n",
    "        self.assertEqual(1, idx)\n",
    "        \n",
    "        idx = YambEnv.convert_row_fill_col_fill(0, 1)\n",
    "        self.assertEqual(14, idx)\n",
    "        \n",
    "        idx = YambEnv.convert_row_fill_col_fill(13, 3)\n",
    "        self.assertEqual(55, idx)\n",
    "    \n",
    "    def test_get_next_dolje(self):\n",
    "        env = YambEnv()\n",
    "        \n",
    "        # start of game nothing is filled out\n",
    "        self.assertEqual(ROW.ONES, ROW(env.get_next_dolje()))\n",
    "        \n",
    "        \n",
    "        # when we add stuff to other columns nothing should change\n",
    "        env.grid[ROW.ONES.value, COL.GORE.value] = 1\n",
    "        env.grid[ROW.ONES.value, COL.SLOBODNO.value] = 1\n",
    "        self.assertEqual(ROW.ONES, ROW(env.get_next_dolje()))\n",
    "        \n",
    "        # when we fill out the rows in order, check the function works as expected\n",
    "        rows = list(ROW)\n",
    "        for row in rows[:-1]:\n",
    "            env.grid[row.value, COL.DOLJE.value] = 0\n",
    "            self.assertEqual(rows[row.value+1], ROW(env.get_next_dolje()))\n",
    "        \n",
    "        # once we've filled everything out check that this returns nan\n",
    "        env.grid[rows[-1].value, COL.DOLJE.value] = 0\n",
    "        self.assertTrue(np.isnan(env.get_next_dolje()))\n",
    "        \n",
    "    def test_get_next_gore(self):\n",
    "        env = YambEnv()\n",
    "        \n",
    "        # start of game nothing is filled out\n",
    "        self.assertEqual(ROW.YAMB, ROW(env.get_next_gore()))\n",
    "        \n",
    "        \n",
    "        # when we add stuff to other columns nothing should change\n",
    "        env.grid[ROW.YAMB.value, COL.DOLJE.value] = 1\n",
    "        env.grid[ROW.YAMB.value, COL.SLOBODNO.value] = 1\n",
    "        self.assertEqual(ROW.YAMB, ROW(env.get_next_gore()))\n",
    "        \n",
    "        # when we fill out the rows in order, check the function works as expected\n",
    "        rows = list(ROW)\n",
    "        for row in reversed(rows[1:]):\n",
    "            env.grid[row.value, COL.GORE.value] = 0\n",
    "            self.assertEqual(rows[row.value-1], ROW(env.get_next_gore()))\n",
    "        \n",
    "        # once we've filled everything out check that this returns nan\n",
    "        env.grid[rows[0].value, COL.GORE.value] = 0\n",
    "        self.assertTrue(np.isnan(env.get_next_gore()))\n",
    "        \n",
    "    def test_get_score(self):\n",
    "        env = YambEnv()\n",
    "        self.assertEqual(0, env.get_score())\n",
    "        \n",
    "        env.grid = np.array(\n",
    "        [[-145, -145, -145, -145],\n",
    "         [-145, -145, -145, -145],\n",
    "         [-145, -145, -145, -145],\n",
    "         [-145, -145, -145, -145],\n",
    "         [-145, -145, -145, -145],\n",
    "         [-145, -145, -145, -145],\n",
    "         [-145, -145, -145, -145],\n",
    "         [-145, -145, -145, -145],\n",
    "         [-145, -145, -145, -145],\n",
    "         [-145, -145, -145, -145],\n",
    "         [-145, -145, -145, -145],\n",
    "         [-145, -145, -145, -145],\n",
    "         [-145, -145, -145, -145],\n",
    "         [-145, -145, -145, -145]]\n",
    "        )\n",
    "        self.assertEqual(0, env.get_score())\n",
    "        \n",
    "        env.grid = np.array(\n",
    "        [[1     , -145, 2     , -145],\n",
    "         [-145, -145, -145, -145],\n",
    "         [-145, -145, -145, -145],\n",
    "         [-145, -145, -145, -145],\n",
    "         [-145, -145, -145, -145],\n",
    "         [-145, -145, -145, -145],\n",
    "         [-145, -145, -145, -145],\n",
    "         [-145, -145, 10    , -145],\n",
    "         [-145, -145, -145, -145],\n",
    "         [-145, -145, -145, -145],\n",
    "         [-145, -145, -145, -145],\n",
    "         [-145, -145, -145, -145],\n",
    "         [-145, -145, -145, -145],\n",
    "         [-145, 55    , -145, -145]]\n",
    "        )\n",
    "        self.assertEqual(1+55+2, env.get_score())\n",
    "        \n",
    "        env.grid = np.array(\n",
    "        [[1     , -145, 2     , -145],\n",
    "         [-145, -145, -145, -145],\n",
    "         [-145, -145, -145, -145],\n",
    "         [-145, -145, -145, -145],\n",
    "         [-145, -145, -145, -145],\n",
    "         [-145, -145, -145, -145],\n",
    "         [-145, -145, 20    , -145],\n",
    "         [-145, -145, 10    , -145],\n",
    "         [-145, -145, -145, -145],\n",
    "         [-145, -145, -145, -145],\n",
    "         [-145, -145, -145, -145],\n",
    "         [-145, -145, -145, -145],\n",
    "         [-145, -145, -145, -145],\n",
    "         [-145, 55    , -145, -145]]\n",
    "        )\n",
    "        self.assertEqual(1+55+2+2*(20-10), env.get_score())\n",
    "        \n",
    "        env.grid = np.array(\n",
    "        [[1     , 1     , 1     , 1     ],\n",
    "         [1     , 1     , 1     , 1     ],\n",
    "         [1     , 1     , 1     , 1     ],\n",
    "         [1     , 1     , 1     , 1     ],\n",
    "         [1     , 1     , 1     , 1     ],\n",
    "         [1     , 1     , 1     , 1     ],\n",
    "         [1     , 1     , 1     , 1     ],\n",
    "         [1     , 1     , 1     , 1     ],\n",
    "         [1     , 1     , 1     , 1     ],\n",
    "         [1     , 1     , 1     , 1     ],\n",
    "         [1     , 1     , 1     , 1     ],\n",
    "         [1     , 1     , 1     , 1     ],\n",
    "         [1     , 1     , 1     , 1     ],\n",
    "         [1     , 1     , 1     , 1     ],]\n",
    "        )\n",
    "        self.assertEqual(6*4 + 6*4, env.get_score())\n",
    "        \n",
    "        env.grid = np.array(\n",
    "        [[-145, -145, -145, 2     ],\n",
    "         [-145, -145, -145, 4     ],\n",
    "         [-145, -145, -145, 3     ],\n",
    "         [-145, -145, -145, 12    ],\n",
    "         [-145, -145, -145, 15    ],\n",
    "         [-145, -145, -145, 24    ],\n",
    "         [-145, -145, -145, -145],\n",
    "         [-145, -145, -145, -145],\n",
    "         [-145, -145, -145, -145],\n",
    "         [-145, -145, -145, -145],\n",
    "         [-145, -145, -145, -145],\n",
    "         [-145, -145, -145, -145],\n",
    "         [-145, -145, -145, -145],\n",
    "         [-145, -145, -145, -145]]\n",
    "        )\n",
    "        self.assertEqual(90, env.get_score())\n",
    "        \n",
    "        env.grid = np.array(\n",
    "        [[1     , 0     , 6     , 0     ],\n",
    "         [4     , 2     , 12    , 0     ],\n",
    "         [3     , 3     , 15    , 0     ],\n",
    "         [12    , 16    , 20    , 0     ],\n",
    "         [15    , 20    , 25    , 0     ],\n",
    "         [24    , 6     , 30    , 0     ],\n",
    "         [20    , 30    , 10    , 0     ],\n",
    "         [10    , 5     , 5     , 0     ],\n",
    "         [16    , 0     , 20    , 0     ],\n",
    "         [33    , 0     , 0     , 0     ],\n",
    "         [45    , 0     , 0     , 0     ],\n",
    "         [55    , 0     , 0     , 0     ],\n",
    "         [54    , 0     , 0     , 0     ],\n",
    "         [65    , 0     , 0     , 0     ]]\n",
    "        )\n",
    "        self.assertEqual(337+47+188+0, env.get_score())\n",
    "        \n",
    "    def test_valid_announce_row(self):\n",
    "        env = YambEnv()\n",
    "        env.grid = np.array(\n",
    "        [[-145, -145, -145, 2     ],\n",
    "         [-145, -145, -145, 4     ],\n",
    "         [-145, -145, -145, 3     ],\n",
    "         [-145, -145, -145, 12    ],\n",
    "         [-145, -145, -145, 15    ],\n",
    "         [-145, -145, -145, 24    ],\n",
    "         [-145, -145, -145, -145],\n",
    "         [-145, -145, -145, -145],\n",
    "         [-145, -145, -145, -145],\n",
    "         [-145, -145, -145, -145],\n",
    "         [-145, -145, -145, -145],\n",
    "         [-145, -145, -145, -145],\n",
    "         [-145, -145, -145, -145],\n",
    "         [-145, -145, -145, -145]]\n",
    "        )\n",
    "        self.assertFalse(env.valid_announce_row(14))\n",
    "        self.assertFalse(env.valid_announce_row(ROW.SIXES.value))\n",
    "        self.assertTrue(env.valid_announce_row(ROW.MAX.value))\n",
    "        self.assertTrue(env.valid_announce_row(10))\n",
    "        \n",
    "    def test_need_to_announce(self):\n",
    "        env = YambEnv()\n",
    "        env.grid = np.array(\n",
    "        [[1     , 0     , 6     , 0     ],\n",
    "         [4     , 2     , 12    , 0     ],\n",
    "         [3     , 3     , 15    , 0     ],\n",
    "         [12    , 16    , 20    , 0     ],\n",
    "         [15    , 20    , 25    , 0     ],\n",
    "         [24    , 6     , 30    , 0     ],\n",
    "         [20    , 30    , 10    , 0     ],\n",
    "         [10    , 5     , 5     , 0     ],\n",
    "         [16    , 0     , 20    , 0     ],\n",
    "         [33    , 0     , 0     , 0     ],\n",
    "         [45    , 0     , 0     , 0     ],\n",
    "         [55    , 0     , 0     , 0     ],\n",
    "         [54    , 0     , 0     , 0     ],\n",
    "         [65    , 0     , 0     , -145     ]]\n",
    "        )\n",
    "        self.assertTrue(env.need_to_announce())\n",
    "        env.grid = np.array(\n",
    "        [[1     , 0     , 6     , 0     ],\n",
    "         [4     , 2     , 12    , 0     ],\n",
    "         [3     , 3     , 15    , 0     ],\n",
    "         [12    , 16    , 20    , 0     ],\n",
    "         [15    , 20    , 25    , 0     ],\n",
    "         [24    , 6     , 30    , 0     ],\n",
    "         [20    , 30    , 10    , 0     ],\n",
    "         [10    , 5     , 5     , 0     ],\n",
    "         [16    , 0     , 20    , 0     ],\n",
    "         [33    , 0     , 0     , 0     ],\n",
    "         [45    , 0     , 0     , 0     ],\n",
    "         [55    , 0     , -145     , 0     ],\n",
    "         [54    , 0     , 0     , 0     ],\n",
    "         [65    , 0     , 0     , -145     ]]\n",
    "        )\n",
    "        self.assertFalse(env.need_to_announce())\n",
    "        \n",
    "    def test_get_grid_square_value(self):\n",
    "        self.assertEqual(YambEnv.get_grid_square_value(ROW.ONES.value, np.array([1,1,1,1,1,0])), 1)\n",
    "        self.assertEqual(YambEnv.get_grid_square_value(ROW.TWOS.value, np.array([0,2,1,1,1,0])), 4)\n",
    "        self.assertEqual(YambEnv.get_grid_square_value(ROW.THREES.value, np.array([5,0,0,0,0,0])), 0)\n",
    "        self.assertEqual(YambEnv.get_grid_square_value(ROW.FOURS.value, np.array([4,0,0,1,0,0])), 4)\n",
    "        self.assertEqual(YambEnv.get_grid_square_value(ROW.FIVES.value, np.array([0,0,0,0,5,0])), 25)\n",
    "        self.assertEqual(YambEnv.get_grid_square_value(ROW.SIXES.value, np.array([0,1,0,0,0,3])), 18)\n",
    "        \n",
    "        self.assertEqual(YambEnv.get_grid_square_value(ROW.MAX.value, np.array([1,1,1,1,1,0])), 15)\n",
    "        self.assertEqual(YambEnv.get_grid_square_value(ROW.MIN.value, np.array([4,1,0,0,0,0])), 6)\n",
    "        \n",
    "        self.assertEqual(YambEnv.get_grid_square_value(ROW.DVAPARA.value, np.array([4,1,0,0,0,0])), 0)\n",
    "        self.assertEqual(YambEnv.get_grid_square_value(ROW.DVAPARA.value, np.array([2,3,0,0,0,0])), 10+6)\n",
    "        self.assertEqual(YambEnv.get_grid_square_value(ROW.DVAPARA.value, np.array([1,0,0,0,2,2])), 10+22)\n",
    "        \n",
    "        self.assertEqual(YambEnv.get_grid_square_value(ROW.TRIS.value, np.array([4,1,0,0,0,0])), 20+3)\n",
    "        self.assertEqual(YambEnv.get_grid_square_value(ROW.TRIS.value, np.array([2,3,0,0,0,0])), 20+6)\n",
    "        self.assertEqual(YambEnv.get_grid_square_value(ROW.TRIS.value, np.array([1,0,0,0,2,2])), 0)\n",
    "        \n",
    "        self.assertEqual(YambEnv.get_grid_square_value(ROW.SKALA.value, np.array([1,1,1,1,1,0])), 45)\n",
    "        self.assertEqual(YambEnv.get_grid_square_value(ROW.SKALA.value, np.array([1,1,1,1,0,1])), 0)\n",
    "        self.assertEqual(YambEnv.get_grid_square_value(ROW.SKALA.value, np.array([0,1,1,1,1,1])), 50)\n",
    "        self.assertEqual(YambEnv.get_grid_square_value(ROW.SKALA.value, np.array([0,1,2,0,1,1])), 0)\n",
    "        \n",
    "        self.assertEqual(YambEnv.get_grid_square_value(ROW.FULL.value, np.array([0,0,0,0,0,5])), 0)\n",
    "        self.assertEqual(YambEnv.get_grid_square_value(ROW.FULL.value, np.array([0,0,0,0,2,3])), 40 + 28)\n",
    "        self.assertEqual(YambEnv.get_grid_square_value(ROW.FULL.value, np.array([0,0,0,1,2,2])), 0)\n",
    "        self.assertEqual(YambEnv.get_grid_square_value(ROW.FULL.value, np.array([0,0,0,0,3,2])), 40 + 27)\n",
    "        \n",
    "        self.assertEqual(YambEnv.get_grid_square_value(ROW.POKER.value, np.array([0,4,1,0,0,0])), 50+8)\n",
    "        self.assertEqual(YambEnv.get_grid_square_value(ROW.POKER.value, np.array([0,5,0,0,0,0])), 50+8)\n",
    "        self.assertEqual(YambEnv.get_grid_square_value(ROW.POKER.value, np.array([0,0,0,0,2,3])), 0)\n",
    "        \n",
    "        self.assertEqual(YambEnv.get_grid_square_value(ROW.YAMB.value, np.array([0,0,0,0,0,5])), 60+30)\n",
    "        self.assertEqual(YambEnv.get_grid_square_value(ROW.YAMB.value, np.array([0,5,0,0,0,0])), 60+10)\n",
    "        self.assertEqual(YambEnv.get_grid_square_value(ROW.YAMB.value, np.array([0,0,0,0,1,4])), 0)\n",
    "        \n",
    "        \n",
    "    def test_step(self):\n",
    "        env = YambEnv()\n",
    "        observation, _ = env.reset()\n",
    "        \n",
    "        # step should fail because trying to keep more dice than we have\n",
    "        action = np.array([\n",
    "            observation[\"roll\"][0]+1,\n",
    "            observation[\"roll\"][1],\n",
    "            observation[\"roll\"][2],\n",
    "            observation[\"roll\"][3],\n",
    "            observation[\"roll\"][4],\n",
    "            observation[\"roll\"][5],\n",
    "            0,\n",
    "            0,\n",
    "            0 + 0*14,\n",
    "        ], dtype=np.int64)\n",
    "        observation, reward, terminated, truncated, info = env.step(action)\n",
    "        self.assertEqual(reward, env.truncation_penalty)\n",
    "        self.assertEqual(terminated, False)\n",
    "        self.assertEqual(truncated, True)\n",
    "        \n",
    "        # step should pass\n",
    "        action = np.array([\n",
    "            observation[\"roll\"][0],\n",
    "            observation[\"roll\"][1],\n",
    "            observation[\"roll\"][2],\n",
    "            observation[\"roll\"][3],\n",
    "            observation[\"roll\"][4],\n",
    "            observation[\"roll\"][5],\n",
    "            1,\n",
    "            ROW.YAMB.value,\n",
    "            0 + 0*14,\n",
    "        ], dtype=np.int64)\n",
    "        observation, reward, terminated, truncated, info = env.step(action)\n",
    "        self.assertEqual(observation[\"turn_number\"], 0)\n",
    "        self.assertEqual(observation[\"roll_number\"], 1)\n",
    "        for i in range(6):\n",
    "            self.assertEqual(observation[\"roll\"][i], action[i]) # should be the same because we kept everything\n",
    "        \n",
    "        self.assertEqual(info[\"score\"], 0)\n",
    "        self.assertEqual(reward, 0)\n",
    "        self.assertEqual(terminated, False)\n",
    "        self.assertEqual(truncated, False)\n",
    "        last_roll = np.copy(observation[\"roll\"])\n",
    "        \n",
    "        # step should pass\n",
    "        action = np.array([\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            -145,\n",
    "            -145,\n",
    "            -145,\n",
    "        ], dtype=np.int64)\n",
    "        observation, reward, terminated, truncated, info = env.step(action)\n",
    "        self.assertEqual(observation[\"turn_number\"], 0)\n",
    "        self.assertEqual(observation[\"roll_number\"], 2)\n",
    "        with np.testing.assert_raises(AssertionError):\n",
    "            np.testing.assert_array_equal(observation[\"roll\"], last_roll) # roll should be different because we didn't keep anything\n",
    "        self.assertEqual(info[\"score\"], 0)\n",
    "        self.assertEqual(reward, 0)\n",
    "        self.assertEqual(terminated, False)\n",
    "        self.assertEqual(truncated, False)\n",
    "        last_roll = np.copy(observation[\"roll\"])\n",
    "        \n",
    "        # step should fail because we're trying to fill out column which isn't najava\n",
    "        action = np.array([\n",
    "            -145,\n",
    "            -145,\n",
    "            -145,\n",
    "            -145,\n",
    "            -145,\n",
    "            -145,\n",
    "            -145,\n",
    "            -145,\n",
    "            ROW.YAMB.value + 14 * COL.GORE.value,\n",
    "        ], dtype=np.int64)\n",
    "        observation, reward, terminated, truncated, info = env.step(action)\n",
    "        self.assertEqual(reward, env.truncation_penalty)\n",
    "        self.assertEqual(terminated, False)\n",
    "        self.assertEqual(truncated, True)\n",
    "        \n",
    "        # step should fail because we're trying to fill out row which isn't the one announced\n",
    "        action = np.array([\n",
    "            -145,\n",
    "            -145,\n",
    "            -145,\n",
    "            -145,\n",
    "            -145,\n",
    "            -145,\n",
    "            -145,\n",
    "            -145,\n",
    "            ROW.ONES.value + 14 * COL.NAJAVA.value,\n",
    "        ], dtype=np.int64)\n",
    "        observation, reward, terminated, truncated, info = env.step(action)\n",
    "        self.assertEqual(reward, env.truncation_penalty)\n",
    "        self.assertEqual(terminated, False)\n",
    "        self.assertEqual(truncated, True)\n",
    "        \n",
    "        # step should pass\n",
    "        action = np.array([\n",
    "            -145,\n",
    "            -145,\n",
    "            -145,\n",
    "            -145,\n",
    "            -145,\n",
    "            -145,\n",
    "            -145,\n",
    "            -145,\n",
    "            ROW.YAMB.value + 14 * COL.NAJAVA.value,\n",
    "        ], dtype=np.int64)\n",
    "        observation, reward, terminated, truncated, info = env.step(action)\n",
    "        self.assertEqual(observation[\"turn_number\"], 1)\n",
    "        self.assertEqual(observation[\"roll_number\"], 0)\n",
    "        with np.testing.assert_raises(AssertionError):\n",
    "            np.testing.assert_array_equal(observation[\"roll\"], last_roll) # since we're moving onto next turn roll should differ\n",
    "        self.assertEqual(info[\"score\"], 0) # score very likely to be zero because we probs didn't get a yamb\n",
    "        self.assertEqual(terminated, False)\n",
    "        self.assertEqual(truncated, False)\n",
    "        self.assertEqual(observation[\"grid\"][ROW.YAMB.value, COL.NAJAVA.value], info[\"score\"])\n",
    "        last_roll = np.copy(observation[\"roll\"])\n",
    "        \n",
    "        # try to announce row which has already been announced - should fail\n",
    "        action = np.array([\n",
    "            observation[\"roll\"][0],\n",
    "            observation[\"roll\"][1],\n",
    "            observation[\"roll\"][2],\n",
    "            observation[\"roll\"][3],\n",
    "            observation[\"roll\"][4],\n",
    "            observation[\"roll\"][5],\n",
    "            1,\n",
    "            ROW.YAMB.value,\n",
    "            0 + 14 * 0,\n",
    "        ], dtype=np.int64)\n",
    "        observation, reward, terminated, truncated, info = env.step(action)\n",
    "        np.testing.assert_array_equal(observation[\"roll\"], last_roll)  # should be the same because we failed action\n",
    "        self.assertEqual(reward, env.truncation_penalty)\n",
    "        self.assertEqual(terminated, False)\n",
    "        self.assertEqual(truncated, True)\n",
    "        \n",
    "        # step should pass\n",
    "        action = np.array([\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0 + 14 * 0,\n",
    "        ], dtype=np.int64)\n",
    "        observation, reward, terminated, truncated, info = env.step(action)\n",
    "        self.assertEqual(observation[\"turn_number\"], 1)\n",
    "        self.assertEqual(observation[\"roll_number\"], 1)\n",
    "        \n",
    "        # step should pass\n",
    "        action = np.array([\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0 + 14 * 0,\n",
    "        ], dtype=np.int64)\n",
    "        observation, reward, terminated, truncated, info = env.step(action)\n",
    "        self.assertEqual(observation[\"turn_number\"], 1)\n",
    "        self.assertEqual(observation[\"roll_number\"], 2)\n",
    "        \n",
    "        # step should fail as we are trying to fill out halfway down the dolje col\n",
    "        action = np.array([\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            ROW.DVAPARA.value + 14 * COL.DOLJE.value,\n",
    "        ], dtype=np.int64)\n",
    "        observation, reward, terminated, truncated, info = env.step(action)\n",
    "        self.assertTrue(truncated)\n",
    "        self.assertEqual(observation[\"turn_number\"], 1)\n",
    "        self.assertEqual(observation[\"roll_number\"], 2)\n",
    "        \n",
    "        # step should fail as we are trying to fill out halfway up the gore col\n",
    "        action = np.array([\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            ROW.DVAPARA.value + 14 * COL.GORE.value,\n",
    "        ], dtype=np.int64)\n",
    "        observation, reward, terminated, truncated, info = env.step(action)\n",
    "        self.assertTrue(truncated)\n",
    "        self.assertEqual(observation[\"turn_number\"], 1)\n",
    "        self.assertEqual(observation[\"roll_number\"], 2)\n",
    "        \n",
    "        # step should fail as we are trying to fill out najava but we didn't announce\n",
    "        action = np.array([\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            ROW.DVAPARA.value + 14 * COL.NAJAVA.value,\n",
    "        ], dtype=np.int64)\n",
    "        observation, reward, terminated, truncated, info = env.step(action)\n",
    "        self.assertTrue(truncated)\n",
    "        self.assertEqual(observation[\"turn_number\"], 1)\n",
    "        self.assertEqual(observation[\"roll_number\"], 2)\n",
    "        \n",
    "        # step should pass\n",
    "        action = np.array([\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            ROW.DVAPARA.value + 14 * COL.SLOBODNO.value,\n",
    "        ], dtype=np.int64)\n",
    "        observation, reward, terminated, truncated, info = env.step(action)\n",
    "        self.assertFalse(truncated)\n",
    "        self.assertEqual(observation[\"turn_number\"], 2)\n",
    "        self.assertEqual(observation[\"roll_number\"], 0)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e1b0afc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_convert_row_col_fill (__main__.TestYambEnv.test_convert_row_col_fill) ... ok\n",
      "test_convert_row_fill_col_fill (__main__.TestYambEnv.test_convert_row_fill_col_fill) ... ok\n",
      "test_get_grid_square_value (__main__.TestYambEnv.test_get_grid_square_value) ... ok\n",
      "test_get_next_dolje (__main__.TestYambEnv.test_get_next_dolje) ... ok\n",
      "test_get_next_gore (__main__.TestYambEnv.test_get_next_gore) ... ok\n",
      "test_get_score (__main__.TestYambEnv.test_get_score) ... ok\n",
      "test_need_to_announce (__main__.TestYambEnv.test_need_to_announce) ... ok\n",
      "test_step (__main__.TestYambEnv.test_step) ... ok\n",
      "test_valid_announce_row (__main__.TestYambEnv.test_valid_announce_row) ... ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 9 tests in 0.041s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.main.TestProgram at 0x23f8abe7440>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unittest.main(argv=[\"\"], verbosity=2, exit=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "406733e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reward:0\n",
      "Reward:0\n",
      "Reward:62\n",
      "Reward:0\n",
      "Reward:0\n",
      "Reward:2\n",
      "Reward:0\n",
      "Reward:0\n",
      "Reward:-1000\n"
     ]
    }
   ],
   "source": [
    "def process_text(s: str) -> NDArray[np.int64]:\n",
    "    num1s, num2s, num3s, num4s, num5s, num6s, announce, announce_row, row_to_fill, col_to_fill = 0,0,0,0,0,0,0,0,0,0\n",
    "    \n",
    "    for c in s:\n",
    "        if c.isnumeric():\n",
    "            if int(c)==1: num1s += 1\n",
    "            if int(c)==2: num2s += 1\n",
    "            if int(c)==3: num3s += 1\n",
    "            if int(c)==4: num4s += 1\n",
    "            if int(c)==5: num5s += 1\n",
    "            if int(c)==6: num6s += 1\n",
    "        else:\n",
    "            break\n",
    "            \n",
    "    try:\n",
    "        index_a = s.index(\"a\")\n",
    "        if s[index_a+1:index_a+3].isnumeric():\n",
    "            announce_row = int(s[index_a+1:index_a+3])\n",
    "        else:\n",
    "            announce_row = int(s[index_a+1:index_a+2])\n",
    "        announce = 1\n",
    "    except ValueError as e:\n",
    "        announce = 0\n",
    "        announce_row = 0\n",
    "        \n",
    "    try:\n",
    "        index_r = s.index(\"r\")\n",
    "        if s[index_r+1:index_r+3].isnumeric():\n",
    "            row_to_fill = int(s[index_r+1:index_r+3])\n",
    "        else:\n",
    "            row_to_fill = int(s[index_r+1:index_r+2])\n",
    "    except ValueError as e:\n",
    "        row_to_fill = 0\n",
    "        \n",
    "    try:\n",
    "        index_c = s.index(\"c\")\n",
    "        if s[index_c+1:index_c+3].isnumeric():\n",
    "            col_to_fill = int(s[index_c+1:index_c+3])\n",
    "        else:\n",
    "            col_to_fill = int(s[index_c+1:index_c+2])\n",
    "    except ValueError as e:\n",
    "        col_to_fill = 0\n",
    "    row_col_fill = YambEnv.convert_row_fill_col_fill(row_to_fill, col_to_fill)\n",
    "    result = np.array([num1s, num2s, num3s, num4s, num5s, num6s, announce, announce_row, row_col_fill])\n",
    "    return result\n",
    "\n",
    "try:\n",
    "    env = YambEnv()\n",
    "    env.reset()\n",
    "    env.render()\n",
    "    run = True\n",
    "    input_box = pygame.Rect(env.SCREEN_WIDTH//2, env.SCREEN_HEIGHT//2+100, 250, 40)\n",
    "    input_box_color = (200, 200, 200)\n",
    "    text = \"\"\n",
    "    text_color = (0, 0, 0)\n",
    "    font = pygame.freetype.Font(None, 20)\n",
    "    while run:\n",
    "        for event in pygame.event.get():\n",
    "            if event.type == pygame.QUIT:\n",
    "                run = False\n",
    "            if event.type == pygame.KEYDOWN:\n",
    "                if event.key == pygame.K_RETURN:\n",
    "                    observation, reward, terminated, truncated, info = env.step(process_text(text))\n",
    "                    env.render()\n",
    "                    print(f\"Reward:{reward}\")\n",
    "                    text = \"\"\n",
    "                elif event.key == pygame.K_BACKSPACE:\n",
    "                    text = text[:-1]\n",
    "                else:\n",
    "                    text += event.unicode\n",
    "                    \n",
    "            pygame.draw.rect(env.screen, input_box_color, input_box, 40)\n",
    "            font.render_to(env.screen, (input_box.x+5, input_box.y+5), text, text_color)\n",
    "            env.clock.tick(YambEnv.RENDER_FPS)\n",
    "            pygame.display.flip()\n",
    "            \n",
    "    env.close()\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n",
    "    pygame.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "30b1913c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FlattenGrid(ObservationWrapper):\n",
    "    def __init__(self, env):\n",
    "        super().__init__(env)\n",
    "        self.observation_space = spaces.Dict({\n",
    "            \"turn_number\": spaces.Discrete(len(ROW)*len(COL),start=0),\n",
    "            \"roll_number\": spaces.Discrete(3,start=0),\n",
    "            \"grid\": spaces.Box(low=-1, high=1, shape=(len(ROW)*len(COL),), dtype=float),\n",
    "            \"roll\": spaces.Box(low=-1, high=1, shape=(6,), dtype=float),\n",
    "            \"announced\": spaces.Discrete(2,start=0),\n",
    "            \"announced_row\": spaces.Discrete(len(ROW), start=0),\n",
    "        })\n",
    "\n",
    "    def observation(self, obs):\n",
    "        obs[\"grid\"] = obs[\"grid\"].flatten() / 145.0\n",
    "        obs[\"roll\"] = (obs[\"roll\"] - 1.0) / 5.0 \n",
    "        return obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a00579c1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aledv\\miniconda3\\envs\\yambot-contrib\\Lib\\site-packages\\gymnasium\\core.py:311: UserWarning: \u001b[33mWARN: env.action_masks to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.action_masks` for environment variables or `env.get_wrapper_attr('action_masks')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 168      |\n",
      "|    ep_rew_mean     | 162      |\n",
      "| time/              |          |\n",
      "|    fps             | 133      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 15       |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 168         |\n",
      "|    ep_rew_mean          | 152         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 106         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 38          |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010901859 |\n",
      "|    clip_fraction        | 0.0997      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.76       |\n",
      "|    explained_variance   | 0.00392     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 109         |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0247     |\n",
      "|    value_loss           | 201         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 168          |\n",
      "|    ep_rew_mean          | 151          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 100          |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 60           |\n",
      "|    total_timesteps      | 6144         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0069414447 |\n",
      "|    clip_fraction        | 0.0411       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.78        |\n",
      "|    explained_variance   | 0.117        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 123          |\n",
      "|    n_updates            | 20           |\n",
      "|    policy_gradient_loss | -0.0183      |\n",
      "|    value_loss           | 190          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 168         |\n",
      "|    ep_rew_mean          | 152         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 97          |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 84          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009404462 |\n",
      "|    clip_fraction        | 0.0783      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.72       |\n",
      "|    explained_variance   | 0.169       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 56          |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0223     |\n",
      "|    value_loss           | 216         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 168         |\n",
      "|    ep_rew_mean          | 150         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 95          |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 107         |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009240124 |\n",
      "|    clip_fraction        | 0.0825      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.7        |\n",
      "|    explained_variance   | 0.302       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 114         |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.0247     |\n",
      "|    value_loss           | 202         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 168         |\n",
      "|    ep_rew_mean          | 148         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 93          |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 130         |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008642335 |\n",
      "|    clip_fraction        | 0.0752      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.66       |\n",
      "|    explained_variance   | 0.415       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 65.5        |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.0258     |\n",
      "|    value_loss           | 146         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 168         |\n",
      "|    ep_rew_mean          | 151         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 92          |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 154         |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009396035 |\n",
      "|    clip_fraction        | 0.0739      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.65       |\n",
      "|    explained_variance   | 0.495       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 45.1        |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.0257     |\n",
      "|    value_loss           | 165         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 168         |\n",
      "|    ep_rew_mean          | 151         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 92          |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 177         |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009828497 |\n",
      "|    clip_fraction        | 0.0927      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.62       |\n",
      "|    explained_variance   | 0.594       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 114         |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.0285     |\n",
      "|    value_loss           | 168         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 168         |\n",
      "|    ep_rew_mean          | 153         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 91          |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 200         |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007718494 |\n",
      "|    clip_fraction        | 0.0804      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.63       |\n",
      "|    explained_variance   | 0.603       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 102         |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.0242     |\n",
      "|    value_loss           | 176         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 168         |\n",
      "|    ep_rew_mean          | 155         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 91          |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 224         |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009289462 |\n",
      "|    clip_fraction        | 0.0888      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.59       |\n",
      "|    explained_variance   | 0.678       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 50.3        |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.0294     |\n",
      "|    value_loss           | 155         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 168         |\n",
      "|    ep_rew_mean          | 154         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 90          |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 247         |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009057516 |\n",
      "|    clip_fraction        | 0.0933      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.58       |\n",
      "|    explained_variance   | 0.722       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 44.2        |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.0299     |\n",
      "|    value_loss           | 115         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 168         |\n",
      "|    ep_rew_mean          | 157         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 90          |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 271         |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011519516 |\n",
      "|    clip_fraction        | 0.112       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.58       |\n",
      "|    explained_variance   | 0.603       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 59.3        |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.0294     |\n",
      "|    value_loss           | 141         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 168        |\n",
      "|    ep_rew_mean          | 161        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 90         |\n",
      "|    iterations           | 13         |\n",
      "|    time_elapsed         | 294        |\n",
      "|    total_timesteps      | 26624      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00902119 |\n",
      "|    clip_fraction        | 0.0991     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -2.59      |\n",
      "|    explained_variance   | 0.557      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 63.4       |\n",
      "|    n_updates            | 120        |\n",
      "|    policy_gradient_loss | -0.025     |\n",
      "|    value_loss           | 232        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 168         |\n",
      "|    ep_rew_mean          | 165         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 90          |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 317         |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011008291 |\n",
      "|    clip_fraction        | 0.121       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.58       |\n",
      "|    explained_variance   | 0.681       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 65.3        |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.0317     |\n",
      "|    value_loss           | 139         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 168         |\n",
      "|    ep_rew_mean          | 167         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 89          |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 341         |\n",
      "|    total_timesteps      | 30720       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009458501 |\n",
      "|    clip_fraction        | 0.0936      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.54       |\n",
      "|    explained_variance   | 0.547       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 78          |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.0241     |\n",
      "|    value_loss           | 252         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 168         |\n",
      "|    ep_rew_mean          | 169         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 89          |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 365         |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010899026 |\n",
      "|    clip_fraction        | 0.108       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.54       |\n",
      "|    explained_variance   | 0.698       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 137         |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | -0.0285     |\n",
      "|    value_loss           | 161         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 168         |\n",
      "|    ep_rew_mean          | 166         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 89          |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 388         |\n",
      "|    total_timesteps      | 34816       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010995463 |\n",
      "|    clip_fraction        | 0.11        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.57       |\n",
      "|    explained_variance   | 0.731       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 51.9        |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.0295     |\n",
      "|    value_loss           | 143         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 168          |\n",
      "|    ep_rew_mean          | 166          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 89           |\n",
      "|    iterations           | 18           |\n",
      "|    time_elapsed         | 411          |\n",
      "|    total_timesteps      | 36864        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0100301355 |\n",
      "|    clip_fraction        | 0.106        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.53        |\n",
      "|    explained_variance   | 0.726        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 53.2         |\n",
      "|    n_updates            | 170          |\n",
      "|    policy_gradient_loss | -0.0279      |\n",
      "|    value_loss           | 129          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 168         |\n",
      "|    ep_rew_mean          | 171         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 89          |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 434         |\n",
      "|    total_timesteps      | 38912       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011831797 |\n",
      "|    clip_fraction        | 0.118       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.53       |\n",
      "|    explained_variance   | 0.743       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 59.7        |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.0328     |\n",
      "|    value_loss           | 122         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 168         |\n",
      "|    ep_rew_mean          | 170         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 89          |\n",
      "|    iterations           | 20          |\n",
      "|    time_elapsed         | 457         |\n",
      "|    total_timesteps      | 40960       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010003515 |\n",
      "|    clip_fraction        | 0.106       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.56       |\n",
      "|    explained_variance   | 0.695       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 66.5        |\n",
      "|    n_updates            | 190         |\n",
      "|    policy_gradient_loss | -0.0286     |\n",
      "|    value_loss           | 151         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 168         |\n",
      "|    ep_rew_mean          | 173         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 89          |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 481         |\n",
      "|    total_timesteps      | 43008       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010637162 |\n",
      "|    clip_fraction        | 0.097       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.43       |\n",
      "|    explained_variance   | 0.712       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 74.8        |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | -0.0283     |\n",
      "|    value_loss           | 161         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 168         |\n",
      "|    ep_rew_mean          | 171         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 89          |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 504         |\n",
      "|    total_timesteps      | 45056       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011725765 |\n",
      "|    clip_fraction        | 0.121       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.42       |\n",
      "|    explained_variance   | 0.786       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 42.8        |\n",
      "|    n_updates            | 210         |\n",
      "|    policy_gradient_loss | -0.0319     |\n",
      "|    value_loss           | 105         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 168         |\n",
      "|    ep_rew_mean          | 167         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 89          |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 528         |\n",
      "|    total_timesteps      | 47104       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011196002 |\n",
      "|    clip_fraction        | 0.114       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.41       |\n",
      "|    explained_variance   | 0.806       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 65          |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | -0.0302     |\n",
      "|    value_loss           | 106         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 168          |\n",
      "|    ep_rew_mean          | 175          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 89           |\n",
      "|    iterations           | 24           |\n",
      "|    time_elapsed         | 551          |\n",
      "|    total_timesteps      | 49152        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0111501925 |\n",
      "|    clip_fraction        | 0.117        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.43        |\n",
      "|    explained_variance   | 0.757        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 50.2         |\n",
      "|    n_updates            | 230          |\n",
      "|    policy_gradient_loss | -0.0313      |\n",
      "|    value_loss           | 129          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 168          |\n",
      "|    ep_rew_mean          | 174          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 89           |\n",
      "|    iterations           | 25           |\n",
      "|    time_elapsed         | 574          |\n",
      "|    total_timesteps      | 51200        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0090672355 |\n",
      "|    clip_fraction        | 0.0793       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.4         |\n",
      "|    explained_variance   | 0.698        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 80.5         |\n",
      "|    n_updates            | 240          |\n",
      "|    policy_gradient_loss | -0.0277      |\n",
      "|    value_loss           | 204          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 168         |\n",
      "|    ep_rew_mean          | 178         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 89          |\n",
      "|    iterations           | 26          |\n",
      "|    time_elapsed         | 597         |\n",
      "|    total_timesteps      | 53248       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011281326 |\n",
      "|    clip_fraction        | 0.113       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.37       |\n",
      "|    explained_variance   | 0.841       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 60.3        |\n",
      "|    n_updates            | 250         |\n",
      "|    policy_gradient_loss | -0.0301     |\n",
      "|    value_loss           | 103         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 168         |\n",
      "|    ep_rew_mean          | 180         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 88          |\n",
      "|    iterations           | 27          |\n",
      "|    time_elapsed         | 621         |\n",
      "|    total_timesteps      | 55296       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009965649 |\n",
      "|    clip_fraction        | 0.0896      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.35       |\n",
      "|    explained_variance   | 0.764       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 64.3        |\n",
      "|    n_updates            | 260         |\n",
      "|    policy_gradient_loss | -0.0263     |\n",
      "|    value_loss           | 155         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 168         |\n",
      "|    ep_rew_mean          | 183         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 88          |\n",
      "|    iterations           | 28          |\n",
      "|    time_elapsed         | 644         |\n",
      "|    total_timesteps      | 57344       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010054486 |\n",
      "|    clip_fraction        | 0.0937      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.41       |\n",
      "|    explained_variance   | 0.761       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 75.5        |\n",
      "|    n_updates            | 270         |\n",
      "|    policy_gradient_loss | -0.0277     |\n",
      "|    value_loss           | 169         |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 168       |\n",
      "|    ep_rew_mean          | 187       |\n",
      "| time/                   |           |\n",
      "|    fps                  | 88        |\n",
      "|    iterations           | 29        |\n",
      "|    time_elapsed         | 667       |\n",
      "|    total_timesteps      | 59392     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0090528 |\n",
      "|    clip_fraction        | 0.0815    |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -2.37     |\n",
      "|    explained_variance   | 0.668     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 280       |\n",
      "|    n_updates            | 280       |\n",
      "|    policy_gradient_loss | -0.0244   |\n",
      "|    value_loss           | 269       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 168       |\n",
      "|    ep_rew_mean          | 192       |\n",
      "| time/                   |           |\n",
      "|    fps                  | 88        |\n",
      "|    iterations           | 30        |\n",
      "|    time_elapsed         | 690       |\n",
      "|    total_timesteps      | 61440     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0122201 |\n",
      "|    clip_fraction        | 0.116     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -2.32     |\n",
      "|    explained_variance   | 0.717     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 86.3      |\n",
      "|    n_updates            | 290       |\n",
      "|    policy_gradient_loss | -0.0299   |\n",
      "|    value_loss           | 190       |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 168         |\n",
      "|    ep_rew_mean          | 196         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 88          |\n",
      "|    iterations           | 31          |\n",
      "|    time_elapsed         | 714         |\n",
      "|    total_timesteps      | 63488       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011917383 |\n",
      "|    clip_fraction        | 0.129       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.37       |\n",
      "|    explained_variance   | 0.805       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 51.3        |\n",
      "|    n_updates            | 300         |\n",
      "|    policy_gradient_loss | -0.0331     |\n",
      "|    value_loss           | 116         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 168         |\n",
      "|    ep_rew_mean          | 199         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 88          |\n",
      "|    iterations           | 32          |\n",
      "|    time_elapsed         | 738         |\n",
      "|    total_timesteps      | 65536       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010063059 |\n",
      "|    clip_fraction        | 0.092       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.31       |\n",
      "|    explained_variance   | 0.703       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 107         |\n",
      "|    n_updates            | 310         |\n",
      "|    policy_gradient_loss | -0.0249     |\n",
      "|    value_loss           | 238         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 168         |\n",
      "|    ep_rew_mean          | 204         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 88          |\n",
      "|    iterations           | 33          |\n",
      "|    time_elapsed         | 761         |\n",
      "|    total_timesteps      | 67584       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010055789 |\n",
      "|    clip_fraction        | 0.109       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.31       |\n",
      "|    explained_variance   | 0.776       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 72          |\n",
      "|    n_updates            | 320         |\n",
      "|    policy_gradient_loss | -0.0297     |\n",
      "|    value_loss           | 176         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 168         |\n",
      "|    ep_rew_mean          | 205         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 88          |\n",
      "|    iterations           | 34          |\n",
      "|    time_elapsed         | 783         |\n",
      "|    total_timesteps      | 69632       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010519815 |\n",
      "|    clip_fraction        | 0.109       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.33       |\n",
      "|    explained_variance   | 0.735       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 143         |\n",
      "|    n_updates            | 330         |\n",
      "|    policy_gradient_loss | -0.0304     |\n",
      "|    value_loss           | 190         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 168         |\n",
      "|    ep_rew_mean          | 207         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 88          |\n",
      "|    iterations           | 35          |\n",
      "|    time_elapsed         | 807         |\n",
      "|    total_timesteps      | 71680       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011785102 |\n",
      "|    clip_fraction        | 0.113       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.28       |\n",
      "|    explained_variance   | 0.755       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 52.6        |\n",
      "|    n_updates            | 340         |\n",
      "|    policy_gradient_loss | -0.0305     |\n",
      "|    value_loss           | 140         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 168         |\n",
      "|    ep_rew_mean          | 208         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 88          |\n",
      "|    iterations           | 36          |\n",
      "|    time_elapsed         | 830         |\n",
      "|    total_timesteps      | 73728       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011046788 |\n",
      "|    clip_fraction        | 0.115       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.23       |\n",
      "|    explained_variance   | 0.717       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 141         |\n",
      "|    n_updates            | 350         |\n",
      "|    policy_gradient_loss | -0.0293     |\n",
      "|    value_loss           | 203         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 168        |\n",
      "|    ep_rew_mean          | 208        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 88         |\n",
      "|    iterations           | 37         |\n",
      "|    time_elapsed         | 854        |\n",
      "|    total_timesteps      | 75776      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01089892 |\n",
      "|    clip_fraction        | 0.122      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -2.23      |\n",
      "|    explained_variance   | 0.787      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 99.8       |\n",
      "|    n_updates            | 360        |\n",
      "|    policy_gradient_loss | -0.0307    |\n",
      "|    value_loss           | 193        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 168         |\n",
      "|    ep_rew_mean          | 212         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 88          |\n",
      "|    iterations           | 38          |\n",
      "|    time_elapsed         | 878         |\n",
      "|    total_timesteps      | 77824       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012347698 |\n",
      "|    clip_fraction        | 0.127       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.25       |\n",
      "|    explained_variance   | 0.719       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 92          |\n",
      "|    n_updates            | 370         |\n",
      "|    policy_gradient_loss | -0.0327     |\n",
      "|    value_loss           | 206         |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 168       |\n",
      "|    ep_rew_mean          | 212       |\n",
      "| time/                   |           |\n",
      "|    fps                  | 88        |\n",
      "|    iterations           | 39        |\n",
      "|    time_elapsed         | 901       |\n",
      "|    total_timesteps      | 79872     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0108878 |\n",
      "|    clip_fraction        | 0.108     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -2.31     |\n",
      "|    explained_variance   | 0.755     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 66.7      |\n",
      "|    n_updates            | 380       |\n",
      "|    policy_gradient_loss | -0.0314   |\n",
      "|    value_loss           | 182       |\n",
      "---------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 168          |\n",
      "|    ep_rew_mean          | 207          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 88           |\n",
      "|    iterations           | 40           |\n",
      "|    time_elapsed         | 924          |\n",
      "|    total_timesteps      | 81920        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0113010425 |\n",
      "|    clip_fraction        | 0.114        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.24        |\n",
      "|    explained_variance   | 0.802        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 41.5         |\n",
      "|    n_updates            | 390          |\n",
      "|    policy_gradient_loss | -0.0295      |\n",
      "|    value_loss           | 162          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 168         |\n",
      "|    ep_rew_mean          | 208         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 88          |\n",
      "|    iterations           | 41          |\n",
      "|    time_elapsed         | 948         |\n",
      "|    total_timesteps      | 83968       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010933209 |\n",
      "|    clip_fraction        | 0.123       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.25       |\n",
      "|    explained_variance   | 0.846       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 35.5        |\n",
      "|    n_updates            | 400         |\n",
      "|    policy_gradient_loss | -0.0331     |\n",
      "|    value_loss           | 109         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 168         |\n",
      "|    ep_rew_mean          | 209         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 88          |\n",
      "|    iterations           | 42          |\n",
      "|    time_elapsed         | 971         |\n",
      "|    total_timesteps      | 86016       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011177734 |\n",
      "|    clip_fraction        | 0.107       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.17       |\n",
      "|    explained_variance   | 0.771       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 55.4        |\n",
      "|    n_updates            | 410         |\n",
      "|    policy_gradient_loss | -0.0279     |\n",
      "|    value_loss           | 214         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 168         |\n",
      "|    ep_rew_mean          | 213         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 88          |\n",
      "|    iterations           | 43          |\n",
      "|    time_elapsed         | 995         |\n",
      "|    total_timesteps      | 88064       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009305606 |\n",
      "|    clip_fraction        | 0.107       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.12       |\n",
      "|    explained_variance   | 0.759       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 68.8        |\n",
      "|    n_updates            | 420         |\n",
      "|    policy_gradient_loss | -0.026      |\n",
      "|    value_loss           | 171         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 168         |\n",
      "|    ep_rew_mean          | 212         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 88          |\n",
      "|    iterations           | 44          |\n",
      "|    time_elapsed         | 1018        |\n",
      "|    total_timesteps      | 90112       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010403597 |\n",
      "|    clip_fraction        | 0.0992      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.12       |\n",
      "|    explained_variance   | 0.788       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 50.2        |\n",
      "|    n_updates            | 430         |\n",
      "|    policy_gradient_loss | -0.0259     |\n",
      "|    value_loss           | 197         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 168         |\n",
      "|    ep_rew_mean          | 215         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 88          |\n",
      "|    iterations           | 45          |\n",
      "|    time_elapsed         | 1042        |\n",
      "|    total_timesteps      | 92160       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011755304 |\n",
      "|    clip_fraction        | 0.127       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.06       |\n",
      "|    explained_variance   | 0.804       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 60.3        |\n",
      "|    n_updates            | 440         |\n",
      "|    policy_gradient_loss | -0.0294     |\n",
      "|    value_loss           | 166         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 168         |\n",
      "|    ep_rew_mean          | 218         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 88          |\n",
      "|    iterations           | 46          |\n",
      "|    time_elapsed         | 1065        |\n",
      "|    total_timesteps      | 94208       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010124367 |\n",
      "|    clip_fraction        | 0.0981      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.07       |\n",
      "|    explained_variance   | 0.814       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 45.9        |\n",
      "|    n_updates            | 450         |\n",
      "|    policy_gradient_loss | -0.0264     |\n",
      "|    value_loss           | 191         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 168         |\n",
      "|    ep_rew_mean          | 220         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 88          |\n",
      "|    iterations           | 47          |\n",
      "|    time_elapsed         | 1090        |\n",
      "|    total_timesteps      | 96256       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012607467 |\n",
      "|    clip_fraction        | 0.123       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.08       |\n",
      "|    explained_variance   | 0.81        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 79.9        |\n",
      "|    n_updates            | 460         |\n",
      "|    policy_gradient_loss | -0.0312     |\n",
      "|    value_loss           | 186         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 168        |\n",
      "|    ep_rew_mean          | 227        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 88         |\n",
      "|    iterations           | 48         |\n",
      "|    time_elapsed         | 1114       |\n",
      "|    total_timesteps      | 98304      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01222899 |\n",
      "|    clip_fraction        | 0.129      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.96      |\n",
      "|    explained_variance   | 0.81       |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 81.9       |\n",
      "|    n_updates            | 470        |\n",
      "|    policy_gradient_loss | -0.0289    |\n",
      "|    value_loss           | 191        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 168         |\n",
      "|    ep_rew_mean          | 232         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 88          |\n",
      "|    iterations           | 49          |\n",
      "|    time_elapsed         | 1137        |\n",
      "|    total_timesteps      | 100352      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012110747 |\n",
      "|    clip_fraction        | 0.126       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.99       |\n",
      "|    explained_variance   | 0.835       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 84.8        |\n",
      "|    n_updates            | 480         |\n",
      "|    policy_gradient_loss | -0.0272     |\n",
      "|    value_loss           | 174         |\n",
      "-----------------------------------------\n",
      "Mean reward: 273.8, Std reward: 90.27546732086188\n"
     ]
    }
   ],
   "source": [
    "env = YambEnv()\n",
    "env = FlattenGrid(env)\n",
    "check_env(env)\n",
    "\n",
    "model = MaskablePPO(\"MultiInputPolicy\", env, seed=32, verbose=1)\n",
    "model.learn(100_000)\n",
    "mean_reward, std_reward = evaluate_policy(model, env, n_eval_episodes=20, warn=False)\n",
    "print(f\"Mean reward: {mean_reward}, Std reward: {std_reward}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b0f1233c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"ppo_mask\")\n",
    "del model # remove to demonstrate saving and loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e009828e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Press Enter to continue...\n"
     ]
    }
   ],
   "source": [
    "model = MaskablePPO.load(\"ppo_mask\")\n",
    "try:\n",
    "    env = YambEnv()\n",
    "    env = FlattenGrid(env)\n",
    "    obs, _ = env.reset()\n",
    "    terminated, truncated = False, False\n",
    "    env.render()\n",
    "    while not (terminated or truncated):\n",
    "        time.sleep(1)\n",
    "        action_masks = get_action_masks(env)\n",
    "        action, _states = model.predict(obs, action_masks=action_masks)\n",
    "        obs, reward, terminated, truncated, info = env.step(action)\n",
    "        env.render()\n",
    "        \n",
    "    # This will pause the notebook and wait for the user to press Enter\n",
    "    input(\"Press Enter to continue...\")\n",
    "    env.close()\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n",
    "    pygame.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "88da3aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AddStepsToReward(RewardWrapper):\n",
    "    def __init__(self, env):\n",
    "        super().__init__(env)\n",
    "\n",
    "    def reward(self, reward):\n",
    "        return 100*(self.unwrapped.turn_number*3 + self.unwrapped.roll_number) + reward / 1000.0\n",
    "    \n",
    "env = AddStepsToReward(env)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
