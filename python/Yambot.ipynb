{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "09833dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from dataclasses import dataclass\n",
    "from enum import Enum\n",
    "from typing import Tuple, Dict, Optional\n",
    "from numpy.typing import NDArray\n",
    "import gymnasium as gym\n",
    "from gymnasium import spaces, ObservationWrapper, RewardWrapper\n",
    "from gymnasium.wrappers import NormalizeReward\n",
    "from stable_baselines3 import A2C, PPO\n",
    "import unittest\n",
    "from stable_baselines3.common.env_checker import check_env\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "import time\n",
    "import pygame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ae2ef98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('announced', 1),\n",
       "             ('announcedRow', 13),\n",
       "             ('grid',\n",
       "              array([[  42.994408 ,  -62.997562 ,  -68.993904 ,  122.12161  ],\n",
       "                     [ -53.178562 ,    8.555374 ,  108.92038  ,   22.520004 ],\n",
       "                     [ -63.294456 ,  -48.830235 ,  118.571106 ,   46.168915 ],\n",
       "                     [-103.408455 ,   11.954169 ,   48.969795 ,  -79.106606 ],\n",
       "                     [  62.81583  ,  109.25411  ,  -32.012897 ,   18.621008 ],\n",
       "                     [  76.407135 , -123.20963  ,  108.60091  ,  -35.450405 ],\n",
       "                     [  61.4535   ,  -85.57396  ,   59.16776  ,  -81.172714 ],\n",
       "                     [-105.81683  ,   81.855354 ,   79.72387  , -114.904625 ],\n",
       "                     [-119.25676  ,  -35.047894 ,  -59.86784  ,   59.836517 ],\n",
       "                     [ -25.255    ,  -14.151916 ,  -24.582682 ,  130.0696   ],\n",
       "                     [  -3.4902658,  -78.79566  ,   51.89075  ,   40.90445  ],\n",
       "                     [-140.14453  ,   54.376293 ,   -5.0871983,  -82.026405 ],\n",
       "                     [  79.00546  ,   34.882225 ,  -21.988804 ,  -59.51357  ],\n",
       "                     [  65.54667  , -114.58423  ,   82.05075  , -122.363594 ]],\n",
       "                    dtype=float32)),\n",
       "             ('roll', array([2, 5, 5, 4, 2])),\n",
       "             ('rollNumber', 3),\n",
       "             ('turnNumber', 54)])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observation_space_dict = {\n",
    "    \"turnNumber\": spaces.Discrete(14*4,start=1),\n",
    "    \"rollNumber\": spaces.Discrete(3,start=1),\n",
    "    \"grid\": spaces.Box(low=-145, high=145, shape=(14, 4)),\n",
    "    \"announced\": spaces.Discrete(2,start=0),\n",
    "    \"announcedRow\": spaces.Discrete(14, start=0),\n",
    "    \"roll\": spaces.Box(low=0, high=5, shape=(5,), dtype=int),\n",
    "}\n",
    "observation_space = spaces.Dict(observation_space_dict)\n",
    "observation_space.sample()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bc4483d",
   "metadata": {},
   "source": [
    "I think you can use any observation space, but the action space cannot be a dict or a tuple. `Box` space might be better as there seems to be more algorithms that support it. Though `MultiDiscrete` seems to be easier to describe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b4102b93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 5,  2,  4,  5,  0,  2,  1, 11, 10,  0])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# keep: np.array # action type 1 and 2, array of length 6 saying which dice we keep\n",
    "# announce: bool = False # roll_number / action type 1\n",
    "# announce_row: ROW = ROW.YAMB # roll_number / action type 1\n",
    "# row_to_fill: ROW = ROW.YAMB # roll_number / action type 3 \n",
    "# col_to_fill: COL = COL.DOLJE # roll_number / action type 3\n",
    "\n",
    "# the action space can't be a tuple or dictionary, which is tricky\n",
    "number_of_ones_to_keep_range = {\"low\" : 0, \"high\": 5}\n",
    "number_of_twos_to_keep_range = {\"low\" : 0, \"high\": 5}\n",
    "number_of_threes_to_keep_range = {\"low\" : 0, \"high\": 5}\n",
    "number_of_fours_to_keep_range = {\"low\" : 0, \"high\": 5}\n",
    "number_of_fives_to_keep_range = {\"low\" : 0, \"high\": 5}\n",
    "number_of_sixes_to_keep_range = {\"low\" : 0, \"high\": 5}\n",
    "announce_range = {\"low\" : 0, \"high\": 1}\n",
    "announce_row_range = {\"low\" : 0, \"high\": 13}\n",
    "row_to_fill_range = {\"low\": 0, \"high\": 13}\n",
    "col_to_fill_range = {\"low\": 0, \"high\": 3}\n",
    "\n",
    "low = np.array(\n",
    "[\n",
    "    number_of_ones_to_keep_range[\"low\"],\n",
    "    number_of_twos_to_keep_range[\"low\"],\n",
    "    number_of_threes_to_keep_range[\"low\"],\n",
    "    number_of_fours_to_keep_range[\"low\"],\n",
    "    number_of_fives_to_keep_range[\"low\"],\n",
    "    number_of_sixes_to_keep_range[\"low\"],\n",
    "    announce_range[\"low\"],\n",
    "    announce_row_range[\"low\"],\n",
    "    row_to_fill_range[\"low\"],\n",
    "    col_to_fill_range[\"low\"],\n",
    "]\n",
    ")\n",
    "\n",
    "high = np.array(\n",
    "[\n",
    "    number_of_ones_to_keep_range[\"high\"],\n",
    "    number_of_twos_to_keep_range[\"high\"],\n",
    "    number_of_threes_to_keep_range[\"high\"],\n",
    "    number_of_fours_to_keep_range[\"high\"],\n",
    "    number_of_fives_to_keep_range[\"high\"],\n",
    "    number_of_sixes_to_keep_range[\"high\"],\n",
    "    announce_range[\"high\"],\n",
    "    announce_row_range[\"high\"],\n",
    "    row_to_fill_range[\"high\"],\n",
    "    col_to_fill_range[\"high\"],\n",
    "]\n",
    ")\n",
    "\n",
    "action_space = spaces.Box(low=low, high=high, dtype=int)\n",
    "action_space.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "57ca0242",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4,  0,  2,  2,  0,  5,  1,  8, 13,  2], dtype=int64)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action_space = spaces.MultiDiscrete(np.array([6, 6, 6, 6, 6, 6, 2, 14, 14, 4]))\n",
    "action_space.sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24480d4d",
   "metadata": {},
   "source": [
    "# `YambEnv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "90507226",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ROW(Enum):\n",
    "    \"\"\"Enum representing each row in yamb\n",
    "    \"\"\"\n",
    "    ONES=0\n",
    "    TWOS=1\n",
    "    THREES=2\n",
    "    FOURS=3\n",
    "    FIVES=4\n",
    "    SIXES=5\n",
    "    MAX=6\n",
    "    MIN=7\n",
    "    DVAPARA=8\n",
    "    TRIS=9\n",
    "    SKALA=10\n",
    "    FULL=11\n",
    "    POKER=12\n",
    "    YAMB=13\n",
    "    \n",
    "class COL(Enum):\n",
    "    \"\"\"Enum representing each col in yamb\n",
    "    \"\"\"\n",
    "    DOLJE=0\n",
    "    GORE=1\n",
    "    SLOBODNO=2\n",
    "    NAJAVA=3\n",
    "    \n",
    "\n",
    "class YambEnv(gym.Env):\n",
    "    \"\"\"\n",
    "    :param turn_number: This tells us which turn we are on. There are 14 * 4 turns in yamb each consisting of 3 rolls.\n",
    "    :param roll_number: Each round in yamb consists of three rolls. This tells you which roll we are on.\n",
    "    :param grid: This is the 14 * 4 grid in yamb which needs to be filled out. -145 indicates not filled.\n",
    "    :param roll: This tells us the roll we just had in multinomial format. This means roll[2] is the number of 3s.\n",
    "    :param announced: This tells us whether we have announced in our current turn.\n",
    "    :param announced_row: This tells us the row we have announced in our current turn.\n",
    "    \"\"\"\n",
    "    metadata = {\"render_modes\": [\"human\"], \"render_fps\": 10}\n",
    "    NAN = -145\n",
    "    ACTION_ANNOUNCE_IDX = 6\n",
    "    ACTION_ANNOUNCE_ROW_IDX = 7\n",
    "    ACTION_ROW_TO_FILL_IDX = 8\n",
    "    ACTION_COL_TO_FILL_IDX = 9\n",
    "    SCREEN_WIDTH = 640\n",
    "    SCREEN_HEIGHT = 480\n",
    "    \n",
    "    def __init__(self, render_mode: Optional[str] = None):\n",
    "        super().__init__()\n",
    "        self.turn_number = 0\n",
    "        self.roll_number = 0\n",
    "        self.grid = np.full((len(ROW), len(COL)), self.NAN)\n",
    "        self.roll = np.array([0, 0, 0, 0, 0, 0])\n",
    "        self.announced = 0\n",
    "        self.announced_row = 0\n",
    "        \n",
    "        self.observation_space = spaces.Dict({\n",
    "            \"turn_number\": spaces.Discrete(len(ROW)*len(COL),start=0),\n",
    "            \"roll_number\": spaces.Discrete(3,start=0),\n",
    "            \"grid\": spaces.Box(low=-145, high=145, shape=(len(ROW), len(COL)), dtype=int),\n",
    "            \"roll\": spaces.Box(low=0, high=5, shape=(6,), dtype=int),\n",
    "            \"announced\": spaces.Discrete(2,start=0),\n",
    "            \"announced_row\": spaces.Discrete(len(ROW), start=0),\n",
    "        })\n",
    "        \n",
    "        # [num1s, num2s, num3s, num4s, num5s, num6s, announce, announce_row, row_to_fill, col_to_fill]\n",
    "        self.action_space = spaces.MultiDiscrete(np.array([6, 6, 6, 6, 6, 6, 2, len(ROW), len(ROW), len(COL)]))\n",
    "        \n",
    "        self.truncation_penalty = -1000\n",
    "        \n",
    "        # pygame parameters and objects\n",
    "        self.render_mode = render_mode\n",
    "        self.screen = None\n",
    "        self.clock = None\n",
    "    \n",
    "    def reset(self, seed=None, options=None) -> Tuple[dict, dict]:\n",
    "        \"\"\"Reset environment to initial state - remember this also includes rolling the dice\n",
    "        \n",
    "        :return: observation of the initial state along with auxiliary information\n",
    "        \"\"\"\n",
    "        self.turn_number = 0\n",
    "        self.roll_number = 0\n",
    "        for row in ROW:\n",
    "            for col in COL:\n",
    "                self.grid[row.value, col.value] = self.NAN\n",
    "        self.roll = np.random.multinomial(5, [1/6.]*6)\n",
    "        self.announced = 0\n",
    "        self.announced_row = 0\n",
    "        \n",
    "        if self.render_mode == \"human\":\n",
    "            self.render()\n",
    "        \n",
    "        return self.get_observation(), {}\n",
    "    \n",
    "    def step(self, action : NDArray[np.int64]) -> Tuple[dict, float, bool, bool, dict]:\n",
    "        \"\"\" Run one timestep of the environment's dynamics - in total there are 56 turns, and 3 rolls within each turn\n",
    "        \n",
    "        :param action: numpy array of length 10\n",
    "            [num1s, num2s, num3s, num4s, num5s, num6s, announce, announce_row, row_to_fill, col_to_fill]\n",
    "        \n",
    "        :return: observation, reward, terminated, truncated, info\n",
    "            observation:dict\n",
    "            reward:float score - prev score or self.truncation_penalty if the game finishes because of a bad action\n",
    "            terminated:bool true when the game finished properly\n",
    "            truncated:bool true when the game finished due to unforseen circumstances; action was out of bounds\n",
    "            info:dict other relevant information for example the score / why the game truncated?\n",
    "        \"\"\"\n",
    "        \n",
    "        prev_score = self.get_score()\n",
    "        \n",
    "        valid, info = True, {}\n",
    "        if self.roll_number == 0:\n",
    "            valid = self.step_1(action, info)\n",
    "        \n",
    "        if self.roll_number == 1:\n",
    "            valid = self.step_2(action, info)\n",
    "        \n",
    "        if self.roll_number == 2:\n",
    "            valid = self.step_3(action, info)\n",
    "        \n",
    "        if not valid:\n",
    "            return self.get_observation(), self.truncation_penalty, False, True, info\n",
    "        \n",
    "        \n",
    "        if (self.roll_number == 0) or (self.roll_number == 1):\n",
    "            self.roll_number += 1\n",
    "        else:\n",
    "            # we are moving on to the next turn\n",
    "            self.roll_number = 0\n",
    "            self.turn_number += 1\n",
    "            self.announced = 0\n",
    "            self.announced_row = 0\n",
    "            r, c = action[self.ACTION_ROW_TO_FILL_IDX], action[self.ACTION_COL_TO_FILL_IDX]\n",
    "            self.grid[r, c] = self.get_grid_square_value(r, self.roll)\n",
    "            self.roll = np.random.multinomial(5, [1/6.]*6)\n",
    "        \n",
    "        info[\"score\"] = self.get_score()\n",
    "        reward = info[\"score\"] - prev_score\n",
    "        terminated = True if self.turn_number >= len(ROW)*len(COL) else False\n",
    "        \n",
    "        if self.render_mode == \"human\":\n",
    "            self.render()\n",
    "            \n",
    "        return self.get_observation(), reward, terminated, False, info\n",
    "    \n",
    "    def render(self):\n",
    "        \"\"\"Displays the state of the game - there is no interaction with the user here\n",
    "        \"\"\"\n",
    "        if self.screen is None:\n",
    "            pygame.init()\n",
    "            self.screen = pygame.display.set_mode((self.SCREEN_WIDTH, self.SCREEN_HEIGHT), pygame.RESIZABLE)\n",
    "            \n",
    "        if self.clock is None:\n",
    "            self.clock = pygame.time.Clock()\n",
    "            \n",
    "        cell_size = 32\n",
    "        dot_radius = 2\n",
    "        black = (0, 0, 0)\n",
    "        white = (255, 255, 255)\n",
    "        self.screen.fill(white)\n",
    "        \n",
    "        font = pygame.font.Font(None, 24)\n",
    "        text = font.render(f\"TURN: {self.turn_number}, ROLL: {self.roll_number}\", True, black)\n",
    "        text_rect = text.get_rect()\n",
    "        text_rect.topleft = (self.SCREEN_WIDTH//2, cell_size)\n",
    "        self.screen.blit(text, text_rect)\n",
    "        \n",
    "        text = font.render(f\"SCORE: {self.get_score()}\", True, black)\n",
    "        text_rect = text.get_rect()\n",
    "        text_rect.topleft = (self.SCREEN_WIDTH//2, 2*cell_size)\n",
    "        self.screen.blit(text, text_rect)\n",
    "        \n",
    "        text = font.render(f\"ANNOUNCED: {bool(self.announced)}\", True, black)\n",
    "        text_rect = text.get_rect()\n",
    "        text_rect.topleft = (self.SCREEN_WIDTH//2, 4*cell_size)\n",
    "        self.screen.blit(text, text_rect)\n",
    "        \n",
    "        if self.announced == 1:\n",
    "            text = font.render(f\"ANNOUNCED ROW: {ROW(self.announced_row)}\", True, black)\n",
    "            text_rect = text.get_rect()\n",
    "            text_rect.topleft = (self.SCREEN_WIDTH//2, 5*cell_size)\n",
    "            self.screen.blit(text, text_rect)\n",
    "        \n",
    "        \n",
    "        \n",
    "        # draw rows\n",
    "        font = pygame.font.Font(None, 12)\n",
    "        for row in ROW:\n",
    "            rect = pygame.Rect(0, (1+row.value)*cell_size, 2*cell_size, cell_size)\n",
    "            text = font.render(str(row.value) + \". \" + row.name, True, black)\n",
    "            pygame.draw.rect(self.screen, black, rect, 1)\n",
    "            self.screen.blit(text, rect.move(cell_size//4, cell_size//4))\n",
    "            \n",
    "        # draw cols\n",
    "        for col in COL:\n",
    "            rect = pygame.Rect((2+2*col.value)*cell_size, 0, 2*cell_size, cell_size)\n",
    "            text = font.render(str(col.value) + \". \" + col.name, True, black)\n",
    "            pygame.draw.rect(self.screen, black, rect, 1)\n",
    "            self.screen.blit(text, rect.move(cell_size//4, cell_size//4))\n",
    "            \n",
    "        # fill out the grid\n",
    "        font = pygame.font.Font(None, 20)\n",
    "        for row in ROW:\n",
    "            for col in COL:\n",
    "                rect = pygame.Rect((2+2*col.value)*cell_size, (1+row.value)*cell_size, 2*cell_size, cell_size)\n",
    "                s = \"\" if self.grid[row.value, col.value] == self.NAN else str(self.grid[row.value, col.value])\n",
    "                text = font.render(s, True, black)\n",
    "                pygame.draw.rect(self.screen, black, rect, 1)\n",
    "                self.screen.blit(text, rect.move(cell_size//4, cell_size//4))\n",
    "                \n",
    "        # draw roll\n",
    "        def draw_dot(position):\n",
    "            pygame.draw.circle(self.screen, black, position, dot_radius)\n",
    "\n",
    "        def draw_one(x, y):\n",
    "            draw_dot((x + cell_size//2, y + cell_size//2))\n",
    "\n",
    "        def draw_two(x, y):\n",
    "            draw_dot((x + cell_size//4, y + cell_size//4))\n",
    "            draw_dot((x + cell_size*3//4, y + cell_size*3//4))\n",
    "\n",
    "        def draw_three(x, y):\n",
    "            draw_dot((x + cell_size//4, y + cell_size//4))\n",
    "            draw_dot((x + cell_size//2, y + cell_size//2))\n",
    "            draw_dot((x + cell_size*3//4, y + cell_size*3//4))\n",
    "\n",
    "        def draw_four(x, y):\n",
    "            draw_dot((x + cell_size//4, y + cell_size//4))\n",
    "            draw_dot((x + cell_size*3//4, y + cell_size//4))\n",
    "            draw_dot((x + cell_size//4, y + cell_size*3//4))\n",
    "            draw_dot((x + cell_size*3//4, y + cell_size*3//4))\n",
    "\n",
    "        def draw_five(x, y):\n",
    "            draw_dot((x + cell_size//4, y + cell_size//4))\n",
    "            draw_dot((x + cell_size*3//4, y + cell_size//4))\n",
    "            draw_dot((x + cell_size//2, y + cell_size//2))\n",
    "            draw_dot((x + cell_size//4, y + cell_size*3//4))\n",
    "            draw_dot((x + cell_size*3//4, y + cell_size*3//4))\n",
    "\n",
    "        def draw_six(x, y):\n",
    "            draw_dot((x + cell_size//4, y + cell_size//4))\n",
    "            draw_dot((x + cell_size*3//4, y + cell_size//4))\n",
    "            draw_dot((x + cell_size//4, y + cell_size//2))\n",
    "            draw_dot((x + cell_size*3//4, y + cell_size//2))\n",
    "            draw_dot((x + cell_size//4, y + cell_size*3//4))\n",
    "            draw_dot((x + cell_size*3//4, y + cell_size*3//4))\n",
    "        \n",
    "        top_left_x, top_left_y = self.SCREEN_WIDTH//2, self.SCREEN_HEIGHT//2\n",
    "        for i, count in enumerate(self.roll):\n",
    "            for die in range(count):\n",
    "                rect = pygame.Rect(top_left_x, top_left_y, cell_size, cell_size)\n",
    "                pygame.draw.rect(self.screen, (0, 0, 0), rect, 1)\n",
    "                \n",
    "                if (i+1)==1: draw_one(top_left_x, top_left_y)\n",
    "                if (i+1)==2: draw_two(top_left_x, top_left_y)\n",
    "                if (i+1)==3: draw_three(top_left_x, top_left_y)\n",
    "                if (i+1)==4: draw_four(top_left_x, top_left_y)\n",
    "                if (i+1)==5: draw_five(top_left_x, top_left_y)\n",
    "                if (i+1)==6: draw_six(top_left_x, top_left_y)\n",
    "                    \n",
    "                top_left_x += cell_size\n",
    "                \n",
    "            \n",
    "        self.clock.tick(self.metadata[\"render_fps\"])\n",
    "        pygame.display.flip()\n",
    "        \n",
    "    \n",
    "    def close(self):\n",
    "        if self.screen is not None:\n",
    "            pygame.display.quit()\n",
    "            pygame.quit()\n",
    "        \n",
    "    def get_observation(self) -> dict:\n",
    "        observation = {\n",
    "            \"turn_number\": self.turn_number,\n",
    "            \"roll_number\": self.roll_number,\n",
    "            \"grid\": self.grid,\n",
    "            \"roll\": self.roll,\n",
    "            \"announced\": self.announced,\n",
    "            \"announced_row\": self.announced_row,\n",
    "        }\n",
    "        return observation\n",
    "        \n",
    "    def step_1(self, action: NDArray[np.int64], info: dict) -> bool:\n",
    "        \"\"\"Does a step of type 1 - only mutates object if it is valid\n",
    "        \n",
    "        :param action: numpy array of length 10\n",
    "            [num1s, num2s, num3s, num4s, num5s, num6s, announce, announce_row, row_to_fill, col_to_fill]\n",
    "        \n",
    "        :return: whether the action was valid or not, truncation reason will be added to info dict\n",
    "        \n",
    "        unused: row_to_fill, col_to_fill\n",
    "        \"\"\"\n",
    "        keep = action[:self.ACTION_ANNOUNCE_IDX]\n",
    "        if any( (self.roll - keep) < 0 ):\n",
    "            info[\"truncation_reason\"] = f\"Can't keep {keep} when you only have {self.roll}\"\n",
    "            return False\n",
    "        \n",
    "        if action[self.ACTION_ANNOUNCE_IDX] == 1:\n",
    "            if not self.valid_announce_row(action[self.ACTION_ANNOUNCE_ROW_IDX]):\n",
    "                info[\"truncation_reason\"] = f\"Announce row {ROW(action[self.ACTION_ANNOUNCE_ROW_IDX])} not valid\"\n",
    "                return False\n",
    "            \n",
    "        if action[self.ACTION_ANNOUNCE_IDX] == 0:\n",
    "            if self.need_to_announce():\n",
    "                info[\"truncation_reason\"] = \"Only najava column left so must use it\"\n",
    "                return False\n",
    "            \n",
    "        number_of_dice_to_roll = sum(self.roll - keep)\n",
    "        self.roll = np.random.multinomial(number_of_dice_to_roll, [1/6.]*6) + keep\n",
    "        self.announced = action[self.ACTION_ANNOUNCE_IDX]\n",
    "        self.announced_row = action[self.ACTION_ANNOUNCE_ROW_IDX]\n",
    "        return True\n",
    "    \n",
    "    def step_2(self, action: NDArray[np.int64], info: dict) -> bool:\n",
    "        \"\"\"Does a step of type 2 - only mutates object if it is valid\n",
    "        \n",
    "        :param action: numpy array of length 10\n",
    "            [num1s, num2s, num3s, num4s, num5s, num6s, announce, announce_row, row_to_fill, col_to_fill]\n",
    "        \n",
    "        :return: whether the action was valid or not, truncation reason will be added to info dict\n",
    "        \n",
    "        unused: announce, announce_row, row_to_fill, col_to_fill\n",
    "        \"\"\"\n",
    "        keep = action[:self.ACTION_ANNOUNCE_IDX]\n",
    "        if any( (self.roll - keep) < 0 ):\n",
    "            info[\"truncation_reason\"] = f\"Can't keep {keep} when you only have {self.roll}\"\n",
    "            return False\n",
    "        \n",
    "        number_of_dice_to_roll = sum(self.roll - keep)\n",
    "        self.roll = np.random.multinomial(number_of_dice_to_roll, [1/6.]*6) + keep\n",
    "        return True\n",
    "    \n",
    "    def step_3(self, action: NDArray[np.int64], info: dict) -> bool:\n",
    "        \"\"\"Does a step of type 3 - only mutates object if it is valid\n",
    "        \n",
    "        :param action: numpy array of length 10\n",
    "            [num1s, num2s, num3s, num4s, num5s, num6s, announce, announce_row, row_to_fill, col_to_fill]\n",
    "        \n",
    "        :return: whether the action was valid or not, truncation reason will be added to info dict\n",
    "        \n",
    "        unused: num1s, num2s, num3s, num4s, num5s, num6s, announce, announce_row\n",
    "        \"\"\"\n",
    "        r, c = action[self.ACTION_ROW_TO_FILL_IDX], action[self.ACTION_COL_TO_FILL_IDX]\n",
    "        if self.grid[r, c] != self.NAN:\n",
    "            info[\"truncation_reason\"] = f\"{r}, {c} already filled in \"\n",
    "            return False\n",
    "        \n",
    "        if (c == COL.GORE.value) and (r != self.get_next_gore()):\n",
    "            info[\"truncation_reason\"] = f\"Gore needed {ROW(self.get_next_gore())} but trying {ROW(r)}\"\n",
    "            return False\n",
    "        \n",
    "        if (c == COL.DOLJE.value) and (r != self.get_next_dolje()):\n",
    "            info[\"truncation_reason\"] = f\"Dolje needed {ROW(self.get_next_dolje())} but trying {ROW(r)}\"\n",
    "            return False\n",
    "        \n",
    "        if self.announced and ((c != COL.NAJAVA.value) or (r != self.announced_row)):\n",
    "            info[\"truncation_reason\"] = f\"Announced {ROW(self.announced_row)} but trying to fill {ROW(r)}, {COL(c)}\"\n",
    "            return False\n",
    "        \n",
    "        if (self.announced==0) and (c == COL.NAJAVA.value):\n",
    "            info[\"truncation_reason\"] = f\"Have not announced so cannot fill out najava column\"\n",
    "            return False\n",
    "        \n",
    "        return True\n",
    "    \n",
    "    def valid_announce_row(self, row: int) -> bool:\n",
    "        \"\"\"\n",
    "        :param row: a row which you which to announce\n",
    "        \n",
    "        :return: bool indicated whether you can actually announce that row\n",
    "        \"\"\"\n",
    "        if row not in ROW:\n",
    "            return False\n",
    "        \n",
    "        if self.grid[row, COL.NAJAVA.value] == self.NAN:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "        \n",
    "    def need_to_announce(self) -> bool:\n",
    "        \"\"\"You must announce on your first roll when the rest of the grid has been filled\n",
    "        :return: whether you need to announce on your first roll\n",
    "        \"\"\"\n",
    "        for col in [COL.DOLJE, COL.GORE, COL.SLOBODNO]:\n",
    "            for row in ROW:\n",
    "                if self.grid[row.value, col.value] == self.NAN:\n",
    "                    # there's something you can fill out\n",
    "                    return False\n",
    "                \n",
    "        return True\n",
    "    \n",
    "    def get_score(self) -> int:\n",
    "        \"\"\"\n",
    "        :return: game score thus far, anything with an nan will be assigned zero\n",
    "        \"\"\"\n",
    "        result = 0\n",
    "        for col in COL:\n",
    "            A = 0\n",
    "            for row in [ROW.ONES, ROW.TWOS, ROW.THREES, ROW.FOURS, ROW.FIVES, ROW.SIXES]:\n",
    "                A += 0 if self.grid[row.value, col.value] == self.NAN else self.grid[row.value, col.value]\n",
    "                \n",
    "            if (A >= 60):\n",
    "                A += 30\n",
    "            \n",
    "            if (self.grid[ROW.MAX.value, col.value] == self.NAN) or \\\n",
    "            (self.grid[ROW.MIN.value, col.value] == self.NAN) or \\\n",
    "            (self.grid[ROW.ONES.value, col.value] == self.NAN):\n",
    "                B = 0\n",
    "            else:\n",
    "                B = self.grid[ROW.MAX.value, col.value] - self.grid[ROW.MIN.value, col.value]\n",
    "                B *= self.grid[ROW.ONES.value, col.value] \n",
    "            \n",
    "            C = 0\n",
    "            for row in [ROW.DVAPARA, ROW.TRIS, ROW.SKALA, ROW.FULL, ROW.POKER, ROW.YAMB]:\n",
    "                C += 0 if self.grid[row.value, col.value] == self.NAN else self.grid[row.value, col.value]\n",
    "                \n",
    "            result = result + A + B + C\n",
    "                \n",
    "        return result\n",
    "    \n",
    "    def get_next_dolje(self) -> Optional[int]:\n",
    "        \"\"\"\n",
    "        Gets the next row we need to fill out in the dolje column, if we've completed it return nan\n",
    "        \"\"\"\n",
    "        for row in ROW:\n",
    "            if self.grid[row.value, COL.DOLJE.value] == self.NAN: return row.value\n",
    "        \n",
    "        return np.nan\n",
    "    \n",
    "    def get_next_gore(self) -> Optional[int]:\n",
    "        \"\"\"\n",
    "        Gets the next row we need to fill out in the gore column, if we've completed it return nan\n",
    "        \"\"\"\n",
    "        for row in reversed(ROW):\n",
    "            if self.grid[row.value, COL.GORE.value] == self.NAN: return row.value\n",
    "        \n",
    "        return np.nan\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_grid_square_value(row: int, cnts: np.array) -> int:\n",
    "        \"\"\"\n",
    "        :param row: which row do you want the grid square value for\n",
    "        :param cnts: array of size six which tells you tells you mapping of face value to how many dice\n",
    "        :return: grid square value\n",
    "        \"\"\"\n",
    "        \n",
    "        if row == ROW.ONES.value:\n",
    "            return 1 * cnts[0]\n",
    "        elif row == ROW.TWOS.value:\n",
    "            return 2 * cnts[1]\n",
    "        elif row == ROW.THREES.value:\n",
    "            return 3 * cnts[2]\n",
    "        elif row == ROW.FOURS.value:\n",
    "            return 4 * cnts[3]\n",
    "        elif row == ROW.FIVES.value:\n",
    "            return 5 * cnts[4]\n",
    "        elif row == ROW.SIXES.value:\n",
    "            return 6 * cnts[5]\n",
    "        elif row == ROW.MAX.value:\n",
    "            return sum( (i+1)*item for i, item in enumerate(cnts) )\n",
    "        elif row == ROW.MIN.value:\n",
    "            return sum( (i+1)*item for i, item in enumerate(cnts) )\n",
    "        elif row == ROW.DVAPARA.value:\n",
    "            return YambEnv.dvapara(cnts)\n",
    "        elif row == ROW.TRIS.value:\n",
    "            return YambEnv.tris(cnts)\n",
    "        elif row == ROW.SKALA.value:\n",
    "            return YambEnv.skala(cnts)\n",
    "        elif row == ROW.FULL.value:\n",
    "            return YambEnv.full(cnts)\n",
    "        elif row == ROW.POKER.value:\n",
    "            return YambEnv.poker(cnts)\n",
    "        elif row == ROW.YAMB.value:\n",
    "            return YambEnv.yamb(cnts)\n",
    "        else:\n",
    "            raise IndexError(f\"Row {row} not found in possible rows\")\n",
    "    \n",
    "    @staticmethod\n",
    "    def dvapara(cnts : np.array) -> int:\n",
    "        if not (sum(cnts >= 2) >= 2): return 0\n",
    "        s = 0\n",
    "        for i, cnt in enumerate(cnts):\n",
    "            if cnt >= 2:\n",
    "                s += 2 * (i+1)\n",
    "        return s + 10\n",
    "    \n",
    "    @staticmethod\n",
    "    def tris(cnts : np.array) -> int:\n",
    "        if not any(cnts >= 3): return 0\n",
    "        s = 0\n",
    "        for i, cnt in enumerate(cnts):\n",
    "            if cnt >= 3:\n",
    "                s += 3 * (i+1)\n",
    "                \n",
    "        return s + 20\n",
    "    \n",
    "    @staticmethod\n",
    "    def skala(cnts : np.array) -> int:\n",
    "        if all(np.array([1,1,1,1,1,0]) == cnts):\n",
    "            return 45\n",
    "        elif all(np.array([0,1,1,1,1,1]) == cnts):\n",
    "            return 50\n",
    "        else:\n",
    "            return 0\n",
    "    \n",
    "    @staticmethod\n",
    "    def full(cnts : np.array) -> int:\n",
    "        if not (any(cnts == 3) * any(cnts == 2)): return 0\n",
    "        s = sum( (i+1)*item for i, item in enumerate(cnts) )\n",
    "        return s + 40\n",
    "    \n",
    "    @staticmethod\n",
    "    def poker(cnts : np.array) -> int:\n",
    "        if not any(cnts >= 4): return 0\n",
    "        s = 0\n",
    "        for i, cnt in enumerate(cnts):\n",
    "            if cnt >= 4:\n",
    "                s += 4 * (i+1)\n",
    "        \n",
    "        return s + 50\n",
    "    \n",
    "    @staticmethod\n",
    "    def yamb(cnts : np.array) -> int:\n",
    "        if not any(cnts >= 5): return 0\n",
    "        s = sum( (i+1)*item for i, item in enumerate(cnts) )\n",
    "        return s + 60\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c125f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestYambEnv(unittest.TestCase):\n",
    "    def test_get_next_dolje(self):\n",
    "        env = YambEnv()\n",
    "        \n",
    "        # start of game nothing is filled out\n",
    "        self.assertEqual(ROW.ONES, ROW(env.get_next_dolje()))\n",
    "        \n",
    "        \n",
    "        # when we add stuff to other columns nothing should change\n",
    "        env.grid[ROW.ONES.value, COL.GORE.value] = 1\n",
    "        env.grid[ROW.ONES.value, COL.SLOBODNO.value] = 1\n",
    "        self.assertEqual(ROW.ONES, ROW(env.get_next_dolje()))\n",
    "        \n",
    "        # when we fill out the rows in order, check the function works as expected\n",
    "        rows = list(ROW)\n",
    "        for row in rows[:-1]:\n",
    "            env.grid[row.value, COL.DOLJE.value] = 0\n",
    "            self.assertEqual(rows[row.value+1], ROW(env.get_next_dolje()))\n",
    "        \n",
    "        # once we've filled everything out check that this returns nan\n",
    "        env.grid[rows[-1].value, COL.DOLJE.value] = 0\n",
    "        self.assertTrue(np.isnan(env.get_next_dolje()))\n",
    "        \n",
    "    def test_get_next_gore(self):\n",
    "        env = YambEnv()\n",
    "        \n",
    "        # start of game nothing is filled out\n",
    "        self.assertEqual(ROW.YAMB, ROW(env.get_next_gore()))\n",
    "        \n",
    "        \n",
    "        # when we add stuff to other columns nothing should change\n",
    "        env.grid[ROW.YAMB.value, COL.DOLJE.value] = 1\n",
    "        env.grid[ROW.YAMB.value, COL.SLOBODNO.value] = 1\n",
    "        self.assertEqual(ROW.YAMB, ROW(env.get_next_gore()))\n",
    "        \n",
    "        # when we fill out the rows in order, check the function works as expected\n",
    "        rows = list(ROW)\n",
    "        for row in reversed(rows[1:]):\n",
    "            env.grid[row.value, COL.GORE.value] = 0\n",
    "            self.assertEqual(rows[row.value-1], ROW(env.get_next_gore()))\n",
    "        \n",
    "        # once we've filled everything out check that this returns nan\n",
    "        env.grid[rows[0].value, COL.GORE.value] = 0\n",
    "        self.assertTrue(np.isnan(env.get_next_gore()))\n",
    "        \n",
    "    def test_get_score(self):\n",
    "        env = YambEnv()\n",
    "        self.assertEqual(0, env.get_score())\n",
    "        \n",
    "        env.grid = np.array(\n",
    "        [[-145, -145, -145, -145],\n",
    "         [-145, -145, -145, -145],\n",
    "         [-145, -145, -145, -145],\n",
    "         [-145, -145, -145, -145],\n",
    "         [-145, -145, -145, -145],\n",
    "         [-145, -145, -145, -145],\n",
    "         [-145, -145, -145, -145],\n",
    "         [-145, -145, -145, -145],\n",
    "         [-145, -145, -145, -145],\n",
    "         [-145, -145, -145, -145],\n",
    "         [-145, -145, -145, -145],\n",
    "         [-145, -145, -145, -145],\n",
    "         [-145, -145, -145, -145],\n",
    "         [-145, -145, -145, -145]]\n",
    "        )\n",
    "        self.assertEqual(0, env.get_score())\n",
    "        \n",
    "        env.grid = np.array(\n",
    "        [[1     , -145, 2     , -145],\n",
    "         [-145, -145, -145, -145],\n",
    "         [-145, -145, -145, -145],\n",
    "         [-145, -145, -145, -145],\n",
    "         [-145, -145, -145, -145],\n",
    "         [-145, -145, -145, -145],\n",
    "         [-145, -145, -145, -145],\n",
    "         [-145, -145, 10    , -145],\n",
    "         [-145, -145, -145, -145],\n",
    "         [-145, -145, -145, -145],\n",
    "         [-145, -145, -145, -145],\n",
    "         [-145, -145, -145, -145],\n",
    "         [-145, -145, -145, -145],\n",
    "         [-145, 55    , -145, -145]]\n",
    "        )\n",
    "        self.assertEqual(1+55+2, env.get_score())\n",
    "        \n",
    "        env.grid = np.array(\n",
    "        [[1     , -145, 2     , -145],\n",
    "         [-145, -145, -145, -145],\n",
    "         [-145, -145, -145, -145],\n",
    "         [-145, -145, -145, -145],\n",
    "         [-145, -145, -145, -145],\n",
    "         [-145, -145, -145, -145],\n",
    "         [-145, -145, 20    , -145],\n",
    "         [-145, -145, 10    , -145],\n",
    "         [-145, -145, -145, -145],\n",
    "         [-145, -145, -145, -145],\n",
    "         [-145, -145, -145, -145],\n",
    "         [-145, -145, -145, -145],\n",
    "         [-145, -145, -145, -145],\n",
    "         [-145, 55    , -145, -145]]\n",
    "        )\n",
    "        self.assertEqual(1+55+2+2*(20-10), env.get_score())\n",
    "        \n",
    "        env.grid = np.array(\n",
    "        [[1     , 1     , 1     , 1     ],\n",
    "         [1     , 1     , 1     , 1     ],\n",
    "         [1     , 1     , 1     , 1     ],\n",
    "         [1     , 1     , 1     , 1     ],\n",
    "         [1     , 1     , 1     , 1     ],\n",
    "         [1     , 1     , 1     , 1     ],\n",
    "         [1     , 1     , 1     , 1     ],\n",
    "         [1     , 1     , 1     , 1     ],\n",
    "         [1     , 1     , 1     , 1     ],\n",
    "         [1     , 1     , 1     , 1     ],\n",
    "         [1     , 1     , 1     , 1     ],\n",
    "         [1     , 1     , 1     , 1     ],\n",
    "         [1     , 1     , 1     , 1     ],\n",
    "         [1     , 1     , 1     , 1     ],]\n",
    "        )\n",
    "        self.assertEqual(6*4 + 6*4, env.get_score())\n",
    "        \n",
    "        env.grid = np.array(\n",
    "        [[-145, -145, -145, 2     ],\n",
    "         [-145, -145, -145, 4     ],\n",
    "         [-145, -145, -145, 3     ],\n",
    "         [-145, -145, -145, 12    ],\n",
    "         [-145, -145, -145, 15    ],\n",
    "         [-145, -145, -145, 24    ],\n",
    "         [-145, -145, -145, -145],\n",
    "         [-145, -145, -145, -145],\n",
    "         [-145, -145, -145, -145],\n",
    "         [-145, -145, -145, -145],\n",
    "         [-145, -145, -145, -145],\n",
    "         [-145, -145, -145, -145],\n",
    "         [-145, -145, -145, -145],\n",
    "         [-145, -145, -145, -145]]\n",
    "        )\n",
    "        self.assertEqual(90, env.get_score())\n",
    "        \n",
    "        env.grid = np.array(\n",
    "        [[1     , 0     , 6     , 0     ],\n",
    "         [4     , 2     , 12    , 0     ],\n",
    "         [3     , 3     , 15    , 0     ],\n",
    "         [12    , 16    , 20    , 0     ],\n",
    "         [15    , 20    , 25    , 0     ],\n",
    "         [24    , 6     , 30    , 0     ],\n",
    "         [20    , 30    , 10    , 0     ],\n",
    "         [10    , 5     , 5     , 0     ],\n",
    "         [16    , 0     , 20    , 0     ],\n",
    "         [33    , 0     , 0     , 0     ],\n",
    "         [45    , 0     , 0     , 0     ],\n",
    "         [55    , 0     , 0     , 0     ],\n",
    "         [54    , 0     , 0     , 0     ],\n",
    "         [65    , 0     , 0     , 0     ]]\n",
    "        )\n",
    "        self.assertEqual(337+47+188+0, env.get_score())\n",
    "        \n",
    "    def test_valid_announce_row(self):\n",
    "        env = YambEnv()\n",
    "        env.grid = np.array(\n",
    "        [[-145, -145, -145, 2     ],\n",
    "         [-145, -145, -145, 4     ],\n",
    "         [-145, -145, -145, 3     ],\n",
    "         [-145, -145, -145, 12    ],\n",
    "         [-145, -145, -145, 15    ],\n",
    "         [-145, -145, -145, 24    ],\n",
    "         [-145, -145, -145, -145],\n",
    "         [-145, -145, -145, -145],\n",
    "         [-145, -145, -145, -145],\n",
    "         [-145, -145, -145, -145],\n",
    "         [-145, -145, -145, -145],\n",
    "         [-145, -145, -145, -145],\n",
    "         [-145, -145, -145, -145],\n",
    "         [-145, -145, -145, -145]]\n",
    "        )\n",
    "        self.assertFalse(env.valid_announce_row(14))\n",
    "        self.assertFalse(env.valid_announce_row(ROW.SIXES.value))\n",
    "        self.assertTrue(env.valid_announce_row(ROW.MAX.value))\n",
    "        self.assertTrue(env.valid_announce_row(10))\n",
    "        \n",
    "    def test_need_to_announce(self):\n",
    "        env = YambEnv()\n",
    "        env.grid = np.array(\n",
    "        [[1     , 0     , 6     , 0     ],\n",
    "         [4     , 2     , 12    , 0     ],\n",
    "         [3     , 3     , 15    , 0     ],\n",
    "         [12    , 16    , 20    , 0     ],\n",
    "         [15    , 20    , 25    , 0     ],\n",
    "         [24    , 6     , 30    , 0     ],\n",
    "         [20    , 30    , 10    , 0     ],\n",
    "         [10    , 5     , 5     , 0     ],\n",
    "         [16    , 0     , 20    , 0     ],\n",
    "         [33    , 0     , 0     , 0     ],\n",
    "         [45    , 0     , 0     , 0     ],\n",
    "         [55    , 0     , 0     , 0     ],\n",
    "         [54    , 0     , 0     , 0     ],\n",
    "         [65    , 0     , 0     , -145     ]]\n",
    "        )\n",
    "        self.assertTrue(env.need_to_announce())\n",
    "        env.grid = np.array(\n",
    "        [[1     , 0     , 6     , 0     ],\n",
    "         [4     , 2     , 12    , 0     ],\n",
    "         [3     , 3     , 15    , 0     ],\n",
    "         [12    , 16    , 20    , 0     ],\n",
    "         [15    , 20    , 25    , 0     ],\n",
    "         [24    , 6     , 30    , 0     ],\n",
    "         [20    , 30    , 10    , 0     ],\n",
    "         [10    , 5     , 5     , 0     ],\n",
    "         [16    , 0     , 20    , 0     ],\n",
    "         [33    , 0     , 0     , 0     ],\n",
    "         [45    , 0     , 0     , 0     ],\n",
    "         [55    , 0     , -145     , 0     ],\n",
    "         [54    , 0     , 0     , 0     ],\n",
    "         [65    , 0     , 0     , -145     ]]\n",
    "        )\n",
    "        self.assertFalse(env.need_to_announce())\n",
    "        \n",
    "    def test_get_grid_square_value(self):\n",
    "        self.assertEqual(YambEnv.get_grid_square_value(ROW.ONES.value, np.array([1,1,1,1,1,0])), 1)\n",
    "        self.assertEqual(YambEnv.get_grid_square_value(ROW.TWOS.value, np.array([0,2,1,1,1,0])), 4)\n",
    "        self.assertEqual(YambEnv.get_grid_square_value(ROW.THREES.value, np.array([5,0,0,0,0,0])), 0)\n",
    "        self.assertEqual(YambEnv.get_grid_square_value(ROW.FOURS.value, np.array([4,0,0,1,0,0])), 4)\n",
    "        self.assertEqual(YambEnv.get_grid_square_value(ROW.FIVES.value, np.array([0,0,0,0,5,0])), 25)\n",
    "        self.assertEqual(YambEnv.get_grid_square_value(ROW.SIXES.value, np.array([0,1,0,0,0,3])), 18)\n",
    "        \n",
    "        self.assertEqual(YambEnv.get_grid_square_value(ROW.MAX.value, np.array([1,1,1,1,1,0])), 15)\n",
    "        self.assertEqual(YambEnv.get_grid_square_value(ROW.MIN.value, np.array([4,1,0,0,0,0])), 6)\n",
    "        \n",
    "        self.assertEqual(YambEnv.get_grid_square_value(ROW.DVAPARA.value, np.array([4,1,0,0,0,0])), 0)\n",
    "        self.assertEqual(YambEnv.get_grid_square_value(ROW.DVAPARA.value, np.array([2,3,0,0,0,0])), 10+6)\n",
    "        self.assertEqual(YambEnv.get_grid_square_value(ROW.DVAPARA.value, np.array([1,0,0,0,2,2])), 10+22)\n",
    "        \n",
    "        self.assertEqual(YambEnv.get_grid_square_value(ROW.TRIS.value, np.array([4,1,0,0,0,0])), 20+3)\n",
    "        self.assertEqual(YambEnv.get_grid_square_value(ROW.TRIS.value, np.array([2,3,0,0,0,0])), 20+6)\n",
    "        self.assertEqual(YambEnv.get_grid_square_value(ROW.TRIS.value, np.array([1,0,0,0,2,2])), 0)\n",
    "        \n",
    "        self.assertEqual(YambEnv.get_grid_square_value(ROW.SKALA.value, np.array([1,1,1,1,1,0])), 45)\n",
    "        self.assertEqual(YambEnv.get_grid_square_value(ROW.SKALA.value, np.array([1,1,1,1,0,1])), 0)\n",
    "        self.assertEqual(YambEnv.get_grid_square_value(ROW.SKALA.value, np.array([0,1,1,1,1,1])), 50)\n",
    "        self.assertEqual(YambEnv.get_grid_square_value(ROW.SKALA.value, np.array([0,1,2,0,1,1])), 0)\n",
    "        \n",
    "        self.assertEqual(YambEnv.get_grid_square_value(ROW.FULL.value, np.array([0,0,0,0,0,5])), 0)\n",
    "        self.assertEqual(YambEnv.get_grid_square_value(ROW.FULL.value, np.array([0,0,0,0,2,3])), 40 + 28)\n",
    "        self.assertEqual(YambEnv.get_grid_square_value(ROW.FULL.value, np.array([0,0,0,1,2,2])), 0)\n",
    "        self.assertEqual(YambEnv.get_grid_square_value(ROW.FULL.value, np.array([0,0,0,0,3,2])), 40 + 27)\n",
    "        \n",
    "        self.assertEqual(YambEnv.get_grid_square_value(ROW.POKER.value, np.array([0,4,1,0,0,0])), 50+8)\n",
    "        self.assertEqual(YambEnv.get_grid_square_value(ROW.POKER.value, np.array([0,5,0,0,0,0])), 50+8)\n",
    "        self.assertEqual(YambEnv.get_grid_square_value(ROW.POKER.value, np.array([0,0,0,0,2,3])), 0)\n",
    "        \n",
    "        self.assertEqual(YambEnv.get_grid_square_value(ROW.YAMB.value, np.array([0,0,0,0,0,5])), 60+30)\n",
    "        self.assertEqual(YambEnv.get_grid_square_value(ROW.YAMB.value, np.array([0,5,0,0,0,0])), 60+10)\n",
    "        self.assertEqual(YambEnv.get_grid_square_value(ROW.YAMB.value, np.array([0,0,0,0,1,4])), 0)\n",
    "        \n",
    "        \n",
    "    def test_step(self):\n",
    "        env = YambEnv()\n",
    "        observation, _ = env.reset()\n",
    "        \n",
    "        # step should fail because trying to keep more dice than we have\n",
    "        action = np.array([\n",
    "            observation[\"roll\"][0]+1,\n",
    "            observation[\"roll\"][1],\n",
    "            observation[\"roll\"][2],\n",
    "            observation[\"roll\"][3],\n",
    "            observation[\"roll\"][4],\n",
    "            observation[\"roll\"][5],\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "        ], dtype=np.int64)\n",
    "        observation, reward, terminated, truncated, info = env.step(action)\n",
    "        self.assertEqual(reward, env.truncation_penalty)\n",
    "        self.assertEqual(terminated, False)\n",
    "        self.assertEqual(truncated, True)\n",
    "        \n",
    "        # step should pass\n",
    "        action = np.array([\n",
    "            observation[\"roll\"][0],\n",
    "            observation[\"roll\"][1],\n",
    "            observation[\"roll\"][2],\n",
    "            observation[\"roll\"][3],\n",
    "            observation[\"roll\"][4],\n",
    "            observation[\"roll\"][5],\n",
    "            1,\n",
    "            ROW.YAMB.value,\n",
    "            0,\n",
    "            0,\n",
    "        ], dtype=np.int64)\n",
    "        observation, reward, terminated, truncated, info = env.step(action)\n",
    "        self.assertEqual(observation[\"turn_number\"], 0)\n",
    "        self.assertEqual(observation[\"roll_number\"], 1)\n",
    "        for i in range(6):\n",
    "            self.assertEqual(observation[\"roll\"][i], action[i]) # should be the same because we kept everything\n",
    "        \n",
    "        self.assertEqual(info[\"score\"], 0)\n",
    "        self.assertEqual(reward, 0)\n",
    "        self.assertEqual(terminated, False)\n",
    "        self.assertEqual(truncated, False)\n",
    "        last_roll = np.copy(observation[\"roll\"])\n",
    "        \n",
    "        # step should pass\n",
    "        action = np.array([\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            -145,\n",
    "            -145,\n",
    "            -145,\n",
    "            -145,\n",
    "        ], dtype=np.int64)\n",
    "        observation, reward, terminated, truncated, info = env.step(action)\n",
    "        self.assertEqual(observation[\"turn_number\"], 0)\n",
    "        self.assertEqual(observation[\"roll_number\"], 2)\n",
    "        with np.testing.assert_raises(AssertionError):\n",
    "            np.testing.assert_array_equal(observation[\"roll\"], last_roll) # roll should be different because we didn't keep anything\n",
    "        self.assertEqual(info[\"score\"], 0)\n",
    "        self.assertEqual(reward, 0)\n",
    "        self.assertEqual(terminated, False)\n",
    "        self.assertEqual(truncated, False)\n",
    "        last_roll = np.copy(observation[\"roll\"])\n",
    "        \n",
    "        # step should fail because we're trying to fill out column which isn't najava\n",
    "        action = np.array([\n",
    "            -145,\n",
    "            -145,\n",
    "            -145,\n",
    "            -145,\n",
    "            -145,\n",
    "            -145,\n",
    "            -145,\n",
    "            -145,\n",
    "            ROW.YAMB.value,\n",
    "            COL.GORE.value,\n",
    "        ], dtype=np.int64)\n",
    "        observation, reward, terminated, truncated, info = env.step(action)\n",
    "        self.assertEqual(reward, env.truncation_penalty)\n",
    "        self.assertEqual(terminated, False)\n",
    "        self.assertEqual(truncated, True)\n",
    "        \n",
    "        # step should fail because we're trying to fill out row which isn't the one announced\n",
    "        action = np.array([\n",
    "            -145,\n",
    "            -145,\n",
    "            -145,\n",
    "            -145,\n",
    "            -145,\n",
    "            -145,\n",
    "            -145,\n",
    "            -145,\n",
    "            ROW.ONES.value,\n",
    "            COL.NAJAVA.value,\n",
    "        ], dtype=np.int64)\n",
    "        observation, reward, terminated, truncated, info = env.step(action)\n",
    "        self.assertEqual(reward, env.truncation_penalty)\n",
    "        self.assertEqual(terminated, False)\n",
    "        self.assertEqual(truncated, True)\n",
    "        \n",
    "        # step should pass\n",
    "        action = np.array([\n",
    "            -145,\n",
    "            -145,\n",
    "            -145,\n",
    "            -145,\n",
    "            -145,\n",
    "            -145,\n",
    "            -145,\n",
    "            -145,\n",
    "            ROW.YAMB.value,\n",
    "            COL.NAJAVA.value,\n",
    "        ], dtype=np.int64)\n",
    "        observation, reward, terminated, truncated, info = env.step(action)\n",
    "        self.assertEqual(observation[\"turn_number\"], 1)\n",
    "        self.assertEqual(observation[\"roll_number\"], 0)\n",
    "        with np.testing.assert_raises(AssertionError):\n",
    "            np.testing.assert_array_equal(observation[\"roll\"], last_roll) # since we're moving onto next turn roll should differ\n",
    "        self.assertEqual(info[\"score\"], 0) # score very likely to be zero because we probs didn't get a yamb\n",
    "        self.assertEqual(terminated, False)\n",
    "        self.assertEqual(truncated, False)\n",
    "        self.assertEqual(observation[\"grid\"][ROW.YAMB.value, COL.NAJAVA.value], info[\"score\"])\n",
    "        last_roll = np.copy(observation[\"roll\"])\n",
    "        \n",
    "        # try to announce row which has already been announced - should fail\n",
    "        action = np.array([\n",
    "            observation[\"roll\"][0],\n",
    "            observation[\"roll\"][1],\n",
    "            observation[\"roll\"][2],\n",
    "            observation[\"roll\"][3],\n",
    "            observation[\"roll\"][4],\n",
    "            observation[\"roll\"][5],\n",
    "            1,\n",
    "            ROW.YAMB.value,\n",
    "            0,\n",
    "            0,\n",
    "        ], dtype=np.int64)\n",
    "        observation, reward, terminated, truncated, info = env.step(action)\n",
    "        np.testing.assert_array_equal(observation[\"roll\"], last_roll)  # should be the same because we failed action\n",
    "        self.assertEqual(reward, env.truncation_penalty)\n",
    "        self.assertEqual(terminated, False)\n",
    "        self.assertEqual(truncated, True)\n",
    "        \n",
    "        # step should pass\n",
    "        action = np.array([\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "        ], dtype=np.int64)\n",
    "        observation, reward, terminated, truncated, info = env.step(action)\n",
    "        self.assertEqual(observation[\"turn_number\"], 1)\n",
    "        self.assertEqual(observation[\"roll_number\"], 1)\n",
    "        \n",
    "        # step should pass\n",
    "        action = np.array([\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "        ], dtype=np.int64)\n",
    "        observation, reward, terminated, truncated, info = env.step(action)\n",
    "        self.assertEqual(observation[\"turn_number\"], 1)\n",
    "        self.assertEqual(observation[\"roll_number\"], 2)\n",
    "        \n",
    "        # step should fail as we are trying to fill out halfway down the dolje col\n",
    "        action = np.array([\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            ROW.DVAPARA.value,\n",
    "            COL.DOLJE.value,\n",
    "        ], dtype=np.int64)\n",
    "        observation, reward, terminated, truncated, info = env.step(action)\n",
    "        self.assertTrue(truncated)\n",
    "        self.assertEqual(observation[\"turn_number\"], 1)\n",
    "        self.assertEqual(observation[\"roll_number\"], 2)\n",
    "        \n",
    "        # step should fail as we are trying to fill out halfway up the gore col\n",
    "        action = np.array([\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            ROW.DVAPARA.value,\n",
    "            COL.GORE.value,\n",
    "        ], dtype=np.int64)\n",
    "        observation, reward, terminated, truncated, info = env.step(action)\n",
    "        self.assertTrue(truncated)\n",
    "        self.assertEqual(observation[\"turn_number\"], 1)\n",
    "        self.assertEqual(observation[\"roll_number\"], 2)\n",
    "        \n",
    "        # step should fail as we are trying to fill out najava but we didn't announce\n",
    "        action = np.array([\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            ROW.DVAPARA.value,\n",
    "            COL.NAJAVA.value,\n",
    "        ], dtype=np.int64)\n",
    "        observation, reward, terminated, truncated, info = env.step(action)\n",
    "        self.assertTrue(truncated)\n",
    "        self.assertEqual(observation[\"turn_number\"], 1)\n",
    "        self.assertEqual(observation[\"roll_number\"], 2)\n",
    "        \n",
    "        # step should pass\n",
    "        action = np.array([\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            ROW.DVAPARA.value,\n",
    "            COL.SLOBODNO.value,\n",
    "        ], dtype=np.int64)\n",
    "        observation, reward, terminated, truncated, info = env.step(action)\n",
    "        self.assertFalse(truncated)\n",
    "        self.assertEqual(observation[\"turn_number\"], 2)\n",
    "        self.assertEqual(observation[\"roll_number\"], 0)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e1b0afc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_get_grid_square_value (__main__.TestYambEnv.test_get_grid_square_value) ... ok\n",
      "test_get_next_dolje (__main__.TestYambEnv.test_get_next_dolje) ... ok\n",
      "test_get_next_gore (__main__.TestYambEnv.test_get_next_gore) ... ok\n",
      "test_get_score (__main__.TestYambEnv.test_get_score) ... ok\n",
      "test_need_to_announce (__main__.TestYambEnv.test_need_to_announce) ... ok\n",
      "test_step (__main__.TestYambEnv.test_step) ... ok\n",
      "test_valid_announce_row (__main__.TestYambEnv.test_valid_announce_row) ... ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 7 tests in 0.038s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.main.TestProgram at 0x226b701d070>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unittest.main(argv=[\"\"], verbosity=2, exit=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "406733e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reward:0\n",
      "Reward:0\n",
      "Reward:8\n",
      "Reward:0\n",
      "Reward:0\n",
      "Reward:6\n",
      "Reward:0\n",
      "Reward:0\n",
      "Reward:-1000\n",
      "Reward:64\n",
      "Reward:0\n",
      "Reward:0\n",
      "Reward:50\n",
      "Reward:0\n",
      "Reward:0\n",
      "Reward:3\n",
      "Reward:0\n",
      "Reward:0\n",
      "Reward:49\n",
      "Reward:0\n",
      "Reward:0\n",
      "Reward:6\n",
      "Reward:0\n",
      "Reward:0\n",
      "Reward:12\n",
      "Reward:0\n",
      "Reward:0\n",
      "Reward:18\n",
      "Reward:0\n",
      "Reward:0\n",
      "Reward:3\n",
      "Reward:0\n",
      "Reward:0\n",
      "Reward:24\n",
      "Reward:0\n",
      "Reward:0\n",
      "Reward:26\n",
      "Reward:0\n",
      "Reward:0\n",
      "Reward:-1000\n",
      "Reward:9\n",
      "Reward:0\n",
      "Reward:0\n",
      "Reward:70\n",
      "Reward:0\n",
      "Reward:0\n",
      "Reward:0\n"
     ]
    }
   ],
   "source": [
    "def process_text(s: str) -> NDArray[np.int64]:\n",
    "    num1s, num2s, num3s, num4s, num5s, num6s, announce, announce_row, row_to_fill, col_to_fill = 0,0,0,0,0,0,0,0,0,0\n",
    "    \n",
    "    for c in s:\n",
    "        if c.isnumeric():\n",
    "            if int(c)==1: num1s += 1\n",
    "            if int(c)==2: num2s += 1\n",
    "            if int(c)==3: num3s += 1\n",
    "            if int(c)==4: num4s += 1\n",
    "            if int(c)==5: num5s += 1\n",
    "            if int(c)==6: num6s += 1\n",
    "        else:\n",
    "            break\n",
    "            \n",
    "    try:\n",
    "        index_a = s.index(\"a\")\n",
    "        if s[index_a+1:index_a+3].isnumeric():\n",
    "            announce_row = int(s[index_a+1:index_a+3])\n",
    "        else:\n",
    "            announce_row = int(s[index_a+1:index_a+2])\n",
    "        announce = 1\n",
    "    except ValueError as e:\n",
    "        announce = 0\n",
    "        announce_row = 0\n",
    "        \n",
    "    try:\n",
    "        index_r = s.index(\"r\")\n",
    "        if s[index_r+1:index_r+3].isnumeric():\n",
    "            row_to_fill = int(s[index_r+1:index_r+3])\n",
    "        else:\n",
    "            row_to_fill = int(s[index_r+1:index_r+2])\n",
    "    except ValueError as e:\n",
    "        row_to_fill = 0\n",
    "        \n",
    "    try:\n",
    "        index_c = s.index(\"c\")\n",
    "        if s[index_c+1:index_c+3].isnumeric():\n",
    "            col_to_fill = int(s[index_c+1:index_c+3])\n",
    "        else:\n",
    "            col_to_fill = int(s[index_c+1:index_c+2])\n",
    "    except ValueError as e:\n",
    "        col_to_fill = 0\n",
    "    \n",
    "    result = np.array([num1s, num2s, num3s, num4s, num5s, num6s, announce, announce_row, row_to_fill, col_to_fill])\n",
    "    return result\n",
    "\n",
    "try:\n",
    "    env = YambEnv(render_mode=\"human\")\n",
    "    env.reset()\n",
    "    run = True\n",
    "    input_box = pygame.Rect(env.SCREEN_WIDTH//2, env.SCREEN_HEIGHT//2+100, 250, 40)\n",
    "    input_box_color = (200, 200, 200)\n",
    "    text = \"\"\n",
    "    text_color = (0, 0, 0)\n",
    "    font = pygame.freetype.Font(None, 20)\n",
    "    while run:\n",
    "        for event in pygame.event.get():\n",
    "            if event.type == pygame.QUIT:\n",
    "                run = False\n",
    "            if event.type == pygame.KEYDOWN:\n",
    "                if event.key == pygame.K_RETURN:\n",
    "                    observation, reward, terminated, truncated, info = env.step(process_text(text))\n",
    "                    print(f\"Reward:{reward}\")\n",
    "                    text = \"\"\n",
    "                elif event.key == pygame.K_BACKSPACE:\n",
    "                    text = text[:-1]\n",
    "                else:\n",
    "                    text += event.unicode\n",
    "                    \n",
    "            pygame.draw.rect(env.screen, input_box_color, input_box, 40)\n",
    "            font.render_to(env.screen, (input_box.x+5, input_box.y+5), text, text_color)\n",
    "            env.clock.tick(env.metadata[\"render_fps\"])\n",
    "            pygame.display.flip()\n",
    "            \n",
    "    env.close()\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n",
    "    pygame.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "30b1913c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FlattenGrid(ObservationWrapper):\n",
    "    def __init__(self, env):\n",
    "        super().__init__(env)\n",
    "        self.observation_space = spaces.Dict({\n",
    "            \"turn_number\": spaces.Discrete(len(ROW)*len(COL),start=0),\n",
    "            \"roll_number\": spaces.Discrete(3,start=0),\n",
    "            \"grid\": spaces.Box(low=-1, high=1, shape=(len(ROW)*len(COL),), dtype=float),\n",
    "            \"roll\": spaces.Box(low=-1, high=1, shape=(6,), dtype=float),\n",
    "            \"announced\": spaces.Discrete(2,start=0),\n",
    "            \"announced_row\": spaces.Discrete(len(ROW), start=0),\n",
    "        })\n",
    "\n",
    "    def observation(self, obs):\n",
    "        obs[\"grid\"] = obs[\"grid\"].flatten() / 300.0\n",
    "        obs[\"roll\"] = (obs[\"roll\"] - 1.0) / 5.0 \n",
    "        return obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a3e11952",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AddStepsToReward(RewardWrapper):\n",
    "    def __init__(self, env):\n",
    "        super().__init__(env)\n",
    "\n",
    "    def reward(self, reward):\n",
    "        return (self.unwrapped.turn_number*3 + self.unwrapped.roll_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a00579c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = YambEnv()\n",
    "env = FlattenGrid(env)\n",
    "env = AddStepsToReward(env)\n",
    "check_env(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "703a1a78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1        |\n",
      "|    ep_rew_mean        | 0        |\n",
      "| time/                 |          |\n",
      "|    fps                | 139      |\n",
      "|    iterations         | 100      |\n",
      "|    time_elapsed       | 3        |\n",
      "|    total_timesteps    | 500      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -17.9    |\n",
      "|    explained_variance | 1        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 99       |\n",
      "|    policy_loss        | 0.00637  |\n",
      "|    value_loss         | 2.41e-07 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1        |\n",
      "|    ep_rew_mean        | 0        |\n",
      "| time/                 |          |\n",
      "|    fps                | 137      |\n",
      "|    iterations         | 200      |\n",
      "|    time_elapsed       | 7        |\n",
      "|    total_timesteps    | 1000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -17.8    |\n",
      "|    explained_variance | 1        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 199      |\n",
      "|    policy_loss        | -0.00227 |\n",
      "|    value_loss         | 6.8e-08  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 1         |\n",
      "|    ep_rew_mean        | 0         |\n",
      "| time/                 |           |\n",
      "|    fps                | 135       |\n",
      "|    iterations         | 300       |\n",
      "|    time_elapsed       | 11        |\n",
      "|    total_timesteps    | 1500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -17.8     |\n",
      "|    explained_variance | 1         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 299       |\n",
      "|    policy_loss        | -0.000326 |\n",
      "|    value_loss         | 1.71e-08  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1        |\n",
      "|    ep_rew_mean        | 0        |\n",
      "| time/                 |          |\n",
      "|    fps                | 135      |\n",
      "|    iterations         | 400      |\n",
      "|    time_elapsed       | 14       |\n",
      "|    total_timesteps    | 2000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -17.8    |\n",
      "|    explained_variance | 1        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 399      |\n",
      "|    policy_loss        | 0.00251  |\n",
      "|    value_loss         | 2.12e-08 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1        |\n",
      "|    ep_rew_mean        | 0        |\n",
      "| time/                 |          |\n",
      "|    fps                | 135      |\n",
      "|    iterations         | 500      |\n",
      "|    time_elapsed       | 18       |\n",
      "|    total_timesteps    | 2500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -17.3    |\n",
      "|    explained_variance | 1        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 499      |\n",
      "|    policy_loss        | 0.00146  |\n",
      "|    value_loss         | 7.09e-09 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1        |\n",
      "|    ep_rew_mean        | 0        |\n",
      "| time/                 |          |\n",
      "|    fps                | 134      |\n",
      "|    iterations         | 600      |\n",
      "|    time_elapsed       | 22       |\n",
      "|    total_timesteps    | 3000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -17.2    |\n",
      "|    explained_variance | 1        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 599      |\n",
      "|    policy_loss        | 0.0151   |\n",
      "|    value_loss         | 7.2e-07  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1.01     |\n",
      "|    ep_rew_mean        | 0.02     |\n",
      "| time/                 |          |\n",
      "|    fps                | 134      |\n",
      "|    iterations         | 700      |\n",
      "|    time_elapsed       | 25       |\n",
      "|    total_timesteps    | 3500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.4    |\n",
      "|    explained_variance | 1        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 699      |\n",
      "|    policy_loss        | -0.00537 |\n",
      "|    value_loss         | 1.37e-07 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 1        |\n",
      "|    ep_rew_mean        | 0        |\n",
      "| time/                 |          |\n",
      "|    fps                | 134      |\n",
      "|    iterations         | 800      |\n",
      "|    time_elapsed       | 29       |\n",
      "|    total_timesteps    | 4000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16      |\n",
      "|    explained_variance | 1        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 799      |\n",
      "|    policy_loss        | 0.000802 |\n",
      "|    value_loss         | 3.37e-08 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 2.63     |\n",
      "|    ep_rew_mean        | 4.23     |\n",
      "| time/                 |          |\n",
      "|    fps                | 135      |\n",
      "|    iterations         | 900      |\n",
      "|    time_elapsed       | 33       |\n",
      "|    total_timesteps    | 4500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -5.45    |\n",
      "|    explained_variance | -0.00156 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 899      |\n",
      "|    policy_loss        | 18.8     |\n",
      "|    value_loss         | 11.1     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 3.05     |\n",
      "|    ep_rew_mean        | 5.69     |\n",
      "| time/                 |          |\n",
      "|    fps                | 137      |\n",
      "|    iterations         | 1000     |\n",
      "|    time_elapsed       | 36       |\n",
      "|    total_timesteps    | 5000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -4.77    |\n",
      "|    explained_variance | 0.00122  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 999      |\n",
      "|    policy_loss        | 26.3     |\n",
      "|    value_loss         | 43.9     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 3.33      |\n",
      "|    ep_rew_mean        | 6.81      |\n",
      "| time/                 |           |\n",
      "|    fps                | 139       |\n",
      "|    iterations         | 1100      |\n",
      "|    time_elapsed       | 39        |\n",
      "|    total_timesteps    | 5500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -3.95     |\n",
      "|    explained_variance | -0.000241 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1099      |\n",
      "|    policy_loss        | 9.26      |\n",
      "|    value_loss         | 7.4       |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 3.46     |\n",
      "|    ep_rew_mean        | 7.4      |\n",
      "| time/                 |          |\n",
      "|    fps                | 140      |\n",
      "|    iterations         | 1200     |\n",
      "|    time_elapsed       | 42       |\n",
      "|    total_timesteps    | 6000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.07    |\n",
      "|    explained_variance | 1.9e-05  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1199     |\n",
      "|    policy_loss        | 25.7     |\n",
      "|    value_loss         | 109      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 3.5      |\n",
      "|    ep_rew_mean        | 7.52     |\n",
      "| time/                 |          |\n",
      "|    fps                | 141      |\n",
      "|    iterations         | 1300     |\n",
      "|    time_elapsed       | 45       |\n",
      "|    total_timesteps    | 6500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -3.26    |\n",
      "|    explained_variance | 5.05e-05 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1299     |\n",
      "|    policy_loss        | 7.44     |\n",
      "|    value_loss         | 6.53     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 3.58      |\n",
      "|    ep_rew_mean        | 7.84      |\n",
      "| time/                 |           |\n",
      "|    fps                | 142       |\n",
      "|    iterations         | 1400      |\n",
      "|    time_elapsed       | 49        |\n",
      "|    total_timesteps    | 7000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -3.12     |\n",
      "|    explained_variance | -1.19e-06 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1399      |\n",
      "|    policy_loss        | 6.73      |\n",
      "|    value_loss         | 6.13      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 3.52      |\n",
      "|    ep_rew_mean        | 7.41      |\n",
      "| time/                 |           |\n",
      "|    fps                | 143       |\n",
      "|    iterations         | 1500      |\n",
      "|    time_elapsed       | 52        |\n",
      "|    total_timesteps    | 7500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -2.5      |\n",
      "|    explained_variance | -8.13e-05 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1499      |\n",
      "|    policy_loss        | 6.34      |\n",
      "|    value_loss         | 6.59      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 3.52      |\n",
      "|    ep_rew_mean        | 7.44      |\n",
      "| time/                 |           |\n",
      "|    fps                | 143       |\n",
      "|    iterations         | 1600      |\n",
      "|    time_elapsed       | 55        |\n",
      "|    total_timesteps    | 8000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -2.69     |\n",
      "|    explained_variance | -2.68e-05 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1599      |\n",
      "|    policy_loss        | 8.1       |\n",
      "|    value_loss         | 7.16      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 3.6       |\n",
      "|    ep_rew_mean        | 7.91      |\n",
      "| time/                 |           |\n",
      "|    fps                | 144       |\n",
      "|    iterations         | 1700      |\n",
      "|    time_elapsed       | 59        |\n",
      "|    total_timesteps    | 8500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -2.27     |\n",
      "|    explained_variance | -2.78e-05 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1699      |\n",
      "|    policy_loss        | 8.5       |\n",
      "|    value_loss         | 10.4      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 3.38      |\n",
      "|    ep_rew_mean        | 6.98      |\n",
      "| time/                 |           |\n",
      "|    fps                | 144       |\n",
      "|    iterations         | 1800      |\n",
      "|    time_elapsed       | 62        |\n",
      "|    total_timesteps    | 9000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.56     |\n",
      "|    explained_variance | -3.02e-05 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1799      |\n",
      "|    policy_loss        | 2.01      |\n",
      "|    value_loss         | 5.3       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 3.43      |\n",
      "|    ep_rew_mean        | 7.14      |\n",
      "| time/                 |           |\n",
      "|    fps                | 144       |\n",
      "|    iterations         | 1900      |\n",
      "|    time_elapsed       | 65        |\n",
      "|    total_timesteps    | 9500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.53     |\n",
      "|    explained_variance | -1.55e-06 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1899      |\n",
      "|    policy_loss        | 7.06      |\n",
      "|    value_loss         | 4.31      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 3.54      |\n",
      "|    ep_rew_mean        | 7.64      |\n",
      "| time/                 |           |\n",
      "|    fps                | 144       |\n",
      "|    iterations         | 2000      |\n",
      "|    time_elapsed       | 69        |\n",
      "|    total_timesteps    | 10000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.53     |\n",
      "|    explained_variance | -1.14e-05 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1999      |\n",
      "|    policy_loss        | 4.55      |\n",
      "|    value_loss         | 5.4       |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 3.35     |\n",
      "|    ep_rew_mean        | 6.73     |\n",
      "| time/                 |          |\n",
      "|    fps                | 145      |\n",
      "|    iterations         | 2100     |\n",
      "|    time_elapsed       | 72       |\n",
      "|    total_timesteps    | 10500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.45    |\n",
      "|    explained_variance | 2.98e-07 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2099     |\n",
      "|    policy_loss        | 1.59     |\n",
      "|    value_loss         | 3.68     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 3.67     |\n",
      "|    ep_rew_mean        | 8.28     |\n",
      "| time/                 |          |\n",
      "|    fps                | 145      |\n",
      "|    iterations         | 2200     |\n",
      "|    time_elapsed       | 75       |\n",
      "|    total_timesteps    | 11000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.45    |\n",
      "|    explained_variance | 4.41e-06 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2199     |\n",
      "|    policy_loss        | 3.45     |\n",
      "|    value_loss         | 12.3     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 3.28      |\n",
      "|    ep_rew_mean        | 6.39      |\n",
      "| time/                 |           |\n",
      "|    fps                | 145       |\n",
      "|    iterations         | 2300      |\n",
      "|    time_elapsed       | 78        |\n",
      "|    total_timesteps    | 11500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.04     |\n",
      "|    explained_variance | -7.75e-06 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 2299      |\n",
      "|    policy_loss        | 0.968     |\n",
      "|    value_loss         | 3.49      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 3.24     |\n",
      "|    ep_rew_mean        | 6.2      |\n",
      "| time/                 |          |\n",
      "|    fps                | 146      |\n",
      "|    iterations         | 2400     |\n",
      "|    time_elapsed       | 82       |\n",
      "|    total_timesteps    | 12000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.879   |\n",
      "|    explained_variance | 3.58e-07 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2399     |\n",
      "|    policy_loss        | 2.19     |\n",
      "|    value_loss         | 79.1     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 3.1       |\n",
      "|    ep_rew_mean        | 5.49      |\n",
      "| time/                 |           |\n",
      "|    fps                | 146       |\n",
      "|    iterations         | 2500      |\n",
      "|    time_elapsed       | 85        |\n",
      "|    total_timesteps    | 12500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.771    |\n",
      "|    explained_variance | -6.79e-06 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 2499      |\n",
      "|    policy_loss        | 1.65      |\n",
      "|    value_loss         | 2.87      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 3        |\n",
      "|    ep_rew_mean        | 5        |\n",
      "| time/                 |          |\n",
      "|    fps                | 146      |\n",
      "|    iterations         | 2600     |\n",
      "|    time_elapsed       | 88       |\n",
      "|    total_timesteps    | 13000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.902   |\n",
      "|    explained_variance | 4.05e-06 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2599     |\n",
      "|    policy_loss        | 0.901    |\n",
      "|    value_loss         | 2.33     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 3.12     |\n",
      "|    ep_rew_mean        | 5.6      |\n",
      "| time/                 |          |\n",
      "|    fps                | 146      |\n",
      "|    iterations         | 2700     |\n",
      "|    time_elapsed       | 92       |\n",
      "|    total_timesteps    | 13500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.881   |\n",
      "|    explained_variance | 4.83e-06 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2699     |\n",
      "|    policy_loss        | 1.36     |\n",
      "|    value_loss         | 2.94     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 3.03      |\n",
      "|    ep_rew_mean        | 5.15      |\n",
      "| time/                 |           |\n",
      "|    fps                | 146       |\n",
      "|    iterations         | 2800      |\n",
      "|    time_elapsed       | 95        |\n",
      "|    total_timesteps    | 14000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.753    |\n",
      "|    explained_variance | -7.63e-06 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 2799      |\n",
      "|    policy_loss        | 0.858     |\n",
      "|    value_loss         | 2.07      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 3        |\n",
      "|    ep_rew_mean        | 5        |\n",
      "| time/                 |          |\n",
      "|    fps                | 146      |\n",
      "|    iterations         | 2900     |\n",
      "|    time_elapsed       | 98       |\n",
      "|    total_timesteps    | 14500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.827   |\n",
      "|    explained_variance | 2.92e-06 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2899     |\n",
      "|    policy_loss        | 0.859    |\n",
      "|    value_loss         | 1.68     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 3         |\n",
      "|    ep_rew_mean        | 5         |\n",
      "| time/                 |           |\n",
      "|    fps                | 147       |\n",
      "|    iterations         | 3000      |\n",
      "|    time_elapsed       | 101       |\n",
      "|    total_timesteps    | 15000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.811    |\n",
      "|    explained_variance | -1.35e-05 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 2999      |\n",
      "|    policy_loss        | 0.963     |\n",
      "|    value_loss         | 2.12      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 3.03      |\n",
      "|    ep_rew_mean        | 5.15      |\n",
      "| time/                 |           |\n",
      "|    fps                | 147       |\n",
      "|    iterations         | 3100      |\n",
      "|    time_elapsed       | 105       |\n",
      "|    total_timesteps    | 15500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.631    |\n",
      "|    explained_variance | -7.51e-06 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 3099      |\n",
      "|    policy_loss        | 0.68      |\n",
      "|    value_loss         | 1.4       |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 3        |\n",
      "|    ep_rew_mean        | 5        |\n",
      "| time/                 |          |\n",
      "|    fps                | 147      |\n",
      "|    iterations         | 3200     |\n",
      "|    time_elapsed       | 108      |\n",
      "|    total_timesteps    | 16000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.386   |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3199     |\n",
      "|    policy_loss        | 0.828    |\n",
      "|    value_loss         | 1.15     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 3         |\n",
      "|    ep_rew_mean        | 5         |\n",
      "| time/                 |           |\n",
      "|    fps                | 147       |\n",
      "|    iterations         | 3300      |\n",
      "|    time_elapsed       | 111       |\n",
      "|    total_timesteps    | 16500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.276    |\n",
      "|    explained_variance | -4.77e-06 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 3299      |\n",
      "|    policy_loss        | 1.2       |\n",
      "|    value_loss         | 1.43      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 3        |\n",
      "|    ep_rew_mean        | 5        |\n",
      "| time/                 |          |\n",
      "|    fps                | 147      |\n",
      "|    iterations         | 3400     |\n",
      "|    time_elapsed       | 115      |\n",
      "|    total_timesteps    | 17000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.325   |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3399     |\n",
      "|    policy_loss        | 0.0696   |\n",
      "|    value_loss         | 0.875    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 3         |\n",
      "|    ep_rew_mean        | 5         |\n",
      "| time/                 |           |\n",
      "|    fps                | 147       |\n",
      "|    iterations         | 3500      |\n",
      "|    time_elapsed       | 118       |\n",
      "|    total_timesteps    | 17500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.196    |\n",
      "|    explained_variance | -6.32e-06 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 3499      |\n",
      "|    policy_loss        | 0.0264    |\n",
      "|    value_loss         | 0.733     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 3         |\n",
      "|    ep_rew_mean        | 5         |\n",
      "| time/                 |           |\n",
      "|    fps                | 147       |\n",
      "|    iterations         | 3600      |\n",
      "|    time_elapsed       | 121       |\n",
      "|    total_timesteps    | 18000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.0723   |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 3599      |\n",
      "|    policy_loss        | 0.0101    |\n",
      "|    value_loss         | 0.892     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 3        |\n",
      "|    ep_rew_mean        | 5        |\n",
      "| time/                 |          |\n",
      "|    fps                | 147      |\n",
      "|    iterations         | 3700     |\n",
      "|    time_elapsed       | 125      |\n",
      "|    total_timesteps    | 18500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0362  |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3699     |\n",
      "|    policy_loss        | 0.00297  |\n",
      "|    value_loss         | 0.489    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 3        |\n",
      "|    ep_rew_mean        | 5        |\n",
      "| time/                 |          |\n",
      "|    fps                | 148      |\n",
      "|    iterations         | 3800     |\n",
      "|    time_elapsed       | 128      |\n",
      "|    total_timesteps    | 19000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0303  |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3799     |\n",
      "|    policy_loss        | 0.00172  |\n",
      "|    value_loss         | 0.437    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 3        |\n",
      "|    ep_rew_mean        | 5        |\n",
      "| time/                 |          |\n",
      "|    fps                | 148      |\n",
      "|    iterations         | 3900     |\n",
      "|    time_elapsed       | 131      |\n",
      "|    total_timesteps    | 19500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0178  |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3899     |\n",
      "|    policy_loss        | 0.00138  |\n",
      "|    value_loss         | 0.493    |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 3        |\n",
      "|    ep_rew_mean        | 5        |\n",
      "| time/                 |          |\n",
      "|    fps                | 148      |\n",
      "|    iterations         | 4000     |\n",
      "|    time_elapsed       | 134      |\n",
      "|    total_timesteps    | 20000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.011   |\n",
      "|    explained_variance | 3.57e-05 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3999     |\n",
      "|    policy_loss        | 0.000455 |\n",
      "|    value_loss         | 0.245    |\n",
      "------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.a2c.a2c.A2C at 0x226c356a6c0>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = A2C(\"MultiInputPolicy\", env, verbose=1)\n",
    "model.learn(total_timesteps=20000)\n",
    "\n",
    "# vec_env = model.get_env()\n",
    "# obs = vec_env.reset()\n",
    "# for i in range(1000):\n",
    "#     action, _state = model.predict(obs, deterministic=True)\n",
    "#     obs, reward, done, info = vec_env.step(action)\n",
    "#     vec_env.render(\"human\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ffb1f37e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "mean_reward, std_reward = evaluate_policy(model, model.get_env(), n_eval_episodes=100)\n",
    "print(mean_reward)\n",
    "print(std_reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0acef006",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aledv\\miniconda3\\envs\\yambot\\Lib\\site-packages\\stable_baselines3\\common\\vec_env\\base_vec_env.py:243: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.\n",
      "  warnings.warn(\"You tried to call render() but no `render_mode` was passed to the env constructor.\")\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "# Enjoy trained agent\n",
    "vec_env = model.get_env()\n",
    "obs = vec_env.reset()\n",
    "for i in range(10):\n",
    "    time.sleep(2)\n",
    "    action, _states = model.predict(obs, deterministic=True)\n",
    "    obs, rewards, dones, info = vec_env.step(action)\n",
    "    vec_env.render()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
